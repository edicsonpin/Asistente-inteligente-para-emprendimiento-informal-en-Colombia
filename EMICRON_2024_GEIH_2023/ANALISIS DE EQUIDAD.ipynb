{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0114d238-0237-4cb0-93ba-1f9e7f4693a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ANALISIS DE EQUIDAD - FAIRNESS DEL MODELO\n",
      "================================================================================\n",
      "\n",
      "[1/5] Cargando modelo y datos...\n",
      "  Test set: (13741, 84)\n",
      "  Grupos disponibles: ['area', 'departamento', 'sector']\n",
      "\n",
      "[2/5] Calculando métricas globales...\n",
      "  Accuracy global: 0.9445\n",
      "  ROC-AUC global: 0.9845\n",
      "\n",
      "[3/5] Analizando equidad por grupos...\n",
      "\n",
      "  Análisis por Área:\n",
      "    18.0: n=609, Acc=0.944, AUC=0.983\n",
      "    70.0: n=858, Acc=0.978, AUC=0.997\n",
      "    68.0: n=809, Acc=0.944, AUC=0.987\n",
      "    20.0: n=550, Acc=0.933, AUC=0.977\n",
      "    17.0: n=513, Acc=0.930, AUC=0.979\n",
      "    50.0: n=566, Acc=0.852, AUC=0.956\n",
      "    44.0: n=537, Acc=0.955, AUC=0.991\n",
      "    76.0: n=756, Acc=0.940, AUC=0.963\n",
      "    13.0: n=822, Acc=0.968, AUC=0.972\n",
      "    1.0: n=200, Acc=0.925, AUC=0.981\n",
      "    63.0: n=389, Acc=0.956, AUC=0.994\n",
      "    5.0: n=809, Acc=0.958, AUC=0.981\n",
      "    11.0: n=365, Acc=0.929, AUC=0.970\n",
      "    47.0: n=683, Acc=0.965, AUC=0.984\n",
      "    19.0: n=536, Acc=0.953, AUC=0.985\n",
      "    52.0: n=1051, Acc=0.963, AUC=0.991\n",
      "    66.0: n=475, Acc=0.909, AUC=0.991\n",
      "    15.0: n=365, Acc=0.929, AUC=0.983\n",
      "    27.0: n=324, Acc=0.969, AUC=0.967\n",
      "    73.0: n=360, Acc=0.914, AUC=0.983\n",
      "    88.0: n=83, Acc=0.940, AUC=0.991\n",
      "    41.0: n=350, Acc=0.923, AUC=0.985\n",
      "    8.0: n=657, Acc=0.965, AUC=0.989\n",
      "    23.0: n=631, Acc=0.965, AUC=0.991\n",
      "    54.0: n=443, Acc=0.898, AUC=0.988\n",
      "\n",
      "  Análisis por Departamento (Top 10):\n",
      "    NARINO: n=1051, Acc=0.963, AUC=0.991\n",
      "    SUCRE: n=858, Acc=0.978, AUC=0.997\n",
      "    BOLIVAR: n=822, Acc=0.968, AUC=0.972\n",
      "    SANTANDER: n=809, Acc=0.944, AUC=0.987\n",
      "    ANTIOQUIA: n=809, Acc=0.958, AUC=0.981\n",
      "    VALLE DEL CAUCA: n=756, Acc=0.940, AUC=0.963\n",
      "    MAGDALENA: n=683, Acc=0.965, AUC=0.984\n",
      "    ATLANTICO: n=657, Acc=0.965, AUC=0.989\n",
      "    CORDOBA: n=631, Acc=0.965, AUC=0.991\n",
      "    CAQUETA: n=609, Acc=0.944, AUC=0.983\n",
      "\n",
      "  Análisis por Sector:\n",
      "    1.0: n=12314, Acc=0.940, AUC=0.984\n",
      "    3.0: n=713, Acc=0.989, AUC=0.955\n",
      "    2.0: n=714, Acc=0.976, AUC=0.964\n",
      "\n",
      "[4/5] Calculando Disparate Impact...\n",
      "\n",
      "  Disparate Impact (Sectores):\n",
      "    1.0 vs 3.0\n",
      "    Ratio: 0.674\n",
      "DISPARIDAD SIGNIFICATIVA\n",
      "\n",
      "[5/5] Generando visualizaciones...\n",
      "11_equidad_area.png\n",
      "12_equidad_departamentos.png\n",
      "13_equidad_sectores.png\n",
      "\n",
      "================================================================================\n",
      "GUARDANDO ANALISIS DE EQUIDAD\n",
      "================================================================================\n",
      "analisis_equidad.pkl\n",
      "equidad_area.csv\n",
      "equidad_departamento.csv\n",
      "equidad_sector.csv\n",
      "\n",
      "================================================================================\n",
      "RESUMEN ANALISIS DE EQUIDAD\n",
      "================================================================================\n",
      "\n",
      "Métricas Globales:\n",
      "  Accuracy: 0.9445\n",
      "  ROC-AUC: 0.9845\n",
      "\n",
      "Disparate Impact:\n",
      "\n",
      "  sector: 0.674 DISPARIDAD\n",
      "\n",
      "Gráficas generadas:\n",
      "  - 11_equidad_area.png (urbano vs rural)\n",
      "  - 12_equidad_departamentos.png (mapa de calor)\n",
      "  - 13_equidad_sectores.png (por sector económico)\n",
      "\n",
      "Archivos CSV:\n",
      "  - equidad_area.csv\n",
      "  - equidad_departamento.csv\n",
      "  - equidad_sector.csv\n",
      "\n",
      "ANALISIS DE EQUIDAD COMPLETADO\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "ANALISIS DE EQUIDAD\n",
    "Evaluar fairness y disparidades del modelo por grupos\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (accuracy_score, roc_auc_score, precision_score, \n",
    "                             recall_score, f1_score, confusion_matrix)\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ANALISIS DE EQUIDAD - FAIRNESS DEL MODELO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "OUTPUT_DIR = 'output_ml_final'\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 1: CARGAR MODELO Y DATOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[1/5] Cargando modelo y datos...\")\n",
    "\n",
    "# Cargar modelo\n",
    "with open(f'{OUTPUT_DIR}/model_balanceado.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "# Cargar datos\n",
    "df = pd.read_csv('FUSION EMICRON 2024 + GEIH 2023/dataset_ml_sin_indices.csv')\n",
    "\n",
    "# Recrear preprocesamiento\n",
    "df['exito_formalizacion'] = (df['formalidad_laboral'] >= 1).astype(int)\n",
    "\n",
    "cols_drop = ['exito_ingresos', 'formalidad_laboral']\n",
    "cols_drop = [c for c in cols_drop if c in df.columns]\n",
    "\n",
    "y = df['exito_formalizacion']\n",
    "X = df.drop(['exito_formalizacion'] + cols_drop, axis=1)\n",
    "\n",
    "# Guardar variables de grupo ANTES de preprocesar\n",
    "grupos = {}\n",
    "if 'area' in df.columns:\n",
    "    grupos['area'] = df['area'].copy()\n",
    "if 'nombre_departamento' in df.columns:\n",
    "    grupos['departamento'] = df['nombre_departamento'].copy()\n",
    "if 'sector_economico' in df.columns:\n",
    "    grupos['sector'] = df['sector_economico'].copy()\n",
    "\n",
    "# Preprocesar\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "for col in num_cols:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "for col in cat_cols:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col] = X[col].fillna('Desconocido')\n",
    "    X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Guardar índices para grupos\n",
    "grupos_test = {k: v.loc[X_test.index] for k, v in grupos.items()}\n",
    "\n",
    "print(f\"  Test set: {X_test.shape}\")\n",
    "print(f\"  Grupos disponibles: {list(grupos_test.keys())}\")\n",
    "\n",
    "# Predicciones\n",
    "y_pred = model.predict(X_test)\n",
    "y_proba = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 2: METRICAS GLOBALES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[2/5] Calculando métricas globales...\")\n",
    "\n",
    "metricas_global = {\n",
    "    'accuracy': accuracy_score(y_test, y_pred),\n",
    "    'roc_auc': roc_auc_score(y_test, y_proba),\n",
    "    'precision': precision_score(y_test, y_pred, zero_division=0),\n",
    "    'recall': recall_score(y_test, y_pred, zero_division=0),\n",
    "    'f1': f1_score(y_test, y_pred, zero_division=0)\n",
    "}\n",
    "\n",
    "print(f\"  Accuracy global: {metricas_global['accuracy']:.4f}\")\n",
    "print(f\"  ROC-AUC global: {metricas_global['roc_auc']:.4f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 3: METRICAS POR GRUPO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[3/5] Analizando equidad por grupos...\")\n",
    "\n",
    "resultados_equidad = {}\n",
    "\n",
    "# Función para calcular métricas por grupo\n",
    "def calcular_metricas_grupo(y_true, y_pred_grupo, y_proba_grupo):\n",
    "    if len(y_true) < 10:  # Muy pocos casos\n",
    "        return None\n",
    "    \n",
    "    return {\n",
    "        'n': len(y_true),\n",
    "        'balance': y_true.mean(),\n",
    "        'accuracy': accuracy_score(y_true, y_pred_grupo),\n",
    "        'roc_auc': roc_auc_score(y_true, y_proba_grupo) if len(np.unique(y_true)) > 1 else np.nan,\n",
    "        'precision': precision_score(y_true, y_pred_grupo, zero_division=0),\n",
    "        'recall': recall_score(y_true, y_pred_grupo, zero_division=0),\n",
    "        'f1': f1_score(y_true, y_pred_grupo, zero_division=0),\n",
    "        'tpr': recall_score(y_true, y_pred_grupo, zero_division=0),  # True Positive Rate\n",
    "        'fpr': ((y_pred_grupo == 1) & (y_true == 0)).sum() / max((y_true == 0).sum(), 1)  # False Positive Rate\n",
    "    }\n",
    "\n",
    "# Análisis por área (urbano/rural)\n",
    "if 'area' in grupos_test:\n",
    "    print(\"\\n  Análisis por Área:\")\n",
    "    resultados_equidad['area'] = {}\n",
    "    \n",
    "    for area_val in grupos_test['area'].unique():\n",
    "        mask = grupos_test['area'] == area_val\n",
    "        \n",
    "        metricas = calcular_metricas_grupo(\n",
    "            y_test[mask],\n",
    "            y_pred[mask],\n",
    "            y_proba[mask]\n",
    "        )\n",
    "        \n",
    "        if metricas:\n",
    "            resultados_equidad['area'][area_val] = metricas\n",
    "            print(f\"    {area_val}: n={metricas['n']}, Acc={metricas['accuracy']:.3f}, AUC={metricas['roc_auc']:.3f}\")\n",
    "\n",
    "# Análisis por departamento\n",
    "if 'departamento' in grupos_test:\n",
    "    print(\"\\n  Análisis por Departamento (Top 10):\")\n",
    "    resultados_equidad['departamento'] = {}\n",
    "    \n",
    "    for dept in grupos_test['departamento'].unique():\n",
    "        mask = grupos_test['departamento'] == dept\n",
    "        \n",
    "        metricas = calcular_metricas_grupo(\n",
    "            y_test[mask],\n",
    "            y_pred[mask],\n",
    "            y_proba[mask]\n",
    "        )\n",
    "        \n",
    "        if metricas:\n",
    "            resultados_equidad['departamento'][dept] = metricas\n",
    "    \n",
    "    # Mostrar top 10 por tamaño\n",
    "    dept_sorted = sorted(resultados_equidad['departamento'].items(), \n",
    "                        key=lambda x: x[1]['n'], reverse=True)\n",
    "    for dept, metricas in dept_sorted[:10]:\n",
    "        print(f\"    {dept}: n={metricas['n']}, Acc={metricas['accuracy']:.3f}, AUC={metricas['roc_auc']:.3f}\")\n",
    "\n",
    "# Análisis por sector\n",
    "if 'sector' in grupos_test:\n",
    "    print(\"\\n  Análisis por Sector:\")\n",
    "    resultados_equidad['sector'] = {}\n",
    "    \n",
    "    for sector_val in grupos_test['sector'].unique():\n",
    "        mask = grupos_test['sector'] == sector_val\n",
    "        \n",
    "        metricas = calcular_metricas_grupo(\n",
    "            y_test[mask],\n",
    "            y_pred[mask],\n",
    "            y_proba[mask]\n",
    "        )\n",
    "        \n",
    "        if metricas:\n",
    "            resultados_equidad['sector'][sector_val] = metricas\n",
    "            print(f\"    {sector_val}: n={metricas['n']}, Acc={metricas['accuracy']:.3f}, AUC={metricas['roc_auc']:.3f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 4: DISPARATE IMPACT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[4/5] Calculando Disparate Impact...\")\n",
    "\n",
    "disparate_impact = {}\n",
    "\n",
    "# DI para área (urbano vs rural)\n",
    "if 'area' in resultados_equidad and len(resultados_equidad['area']) == 2:\n",
    "    areas = list(resultados_equidad['area'].keys())\n",
    "    tpr_0 = resultados_equidad['area'][areas[0]]['tpr']\n",
    "    tpr_1 = resultados_equidad['area'][areas[1]]['tpr']\n",
    "    \n",
    "    di = min(tpr_0, tpr_1) / max(tpr_0, tpr_1) if max(tpr_0, tpr_1) > 0 else 1.0\n",
    "    disparate_impact['area'] = di\n",
    "    \n",
    "    print(f\"\\n  Disparate Impact (Área):\")\n",
    "    print(f\"    Ratio: {di:.3f}\")\n",
    "    if di < 0.8:\n",
    "        print(f\"DISPARIDAD SIGNIFICATIVA (< 0.8)\")\n",
    "    else:\n",
    "        print(f\"Disparidad aceptable (>= 0.8)\")\n",
    "\n",
    "# DI para sectores (comparar sector más grande vs más pequeño)\n",
    "if 'sector' in resultados_equidad and len(resultados_equidad['sector']) > 1:\n",
    "    sectores_sorted = sorted(resultados_equidad['sector'].items(), \n",
    "                            key=lambda x: x[1]['n'], reverse=True)\n",
    "    \n",
    "    if len(sectores_sorted) >= 2:\n",
    "        sector_grande = sectores_sorted[0]\n",
    "        sector_pequeno = sectores_sorted[-1]\n",
    "        \n",
    "        tpr_grande = sector_grande[1]['tpr']\n",
    "        tpr_pequeno = sector_pequeno[1]['tpr']\n",
    "        \n",
    "        di_sector = min(tpr_grande, tpr_pequeno) / max(tpr_grande, tpr_pequeno) if max(tpr_grande, tpr_pequeno) > 0 else 1.0\n",
    "        disparate_impact['sector'] = di_sector\n",
    "        \n",
    "        print(f\"\\n  Disparate Impact (Sectores):\")\n",
    "        print(f\"    {sector_grande[0]} vs {sector_pequeno[0]}\")\n",
    "        print(f\"    Ratio: {di_sector:.3f}\")\n",
    "        if di_sector < 0.8:\n",
    "            print(f\"DISPARIDAD SIGNIFICATIVA\")\n",
    "        else:\n",
    "            print(f\"Disparidad aceptable\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 5: VISUALIZACIONES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[5/5] Generando visualizaciones...\")\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "# 1. Comparación de métricas por área\n",
    "if 'area' in resultados_equidad:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    areas = list(resultados_equidad['area'].keys())\n",
    "    metricas_nombres = ['accuracy', 'roc_auc', 'precision', 'recall', 'f1']\n",
    "    \n",
    "    # Gráfica izquierda: Barras agrupadas\n",
    "    x = np.arange(len(metricas_nombres))\n",
    "    width = 0.35\n",
    "    \n",
    "    valores_area0 = [resultados_equidad['area'][areas[0]][m] for m in metricas_nombres]\n",
    "    valores_area1 = [resultados_equidad['area'][areas[1]][m] for m in metricas_nombres]\n",
    "    \n",
    "    axes[0].bar(x - width/2, valores_area0, width, label=str(areas[0]), alpha=0.8)\n",
    "    axes[0].bar(x + width/2, valores_area1, width, label=str(areas[1]), alpha=0.8)\n",
    "    \n",
    "    axes[0].set_xlabel('Métrica', fontweight='bold')\n",
    "    axes[0].set_ylabel('Valor', fontweight='bold')\n",
    "    axes[0].set_title('Comparación de Métricas por Área', fontweight='bold')\n",
    "    axes[0].set_xticks(x)\n",
    "    axes[0].set_xticklabels(['Accuracy', 'ROC-AUC', 'Precision', 'Recall', 'F1'])\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    axes[0].set_ylim([0, 1.0])\n",
    "    \n",
    "    # Gráfica derecha: Tamaño de grupos\n",
    "    axes[1].bar([str(areas[0]), str(areas[1])], \n",
    "               [resultados_equidad['area'][areas[0]]['n'], \n",
    "                resultados_equidad['area'][areas[1]]['n']], \n",
    "               alpha=0.7, color=['#3498db', '#e74c3c'])\n",
    "    \n",
    "    axes[1].set_xlabel('Área', fontweight='bold')\n",
    "    axes[1].set_ylabel('Número de Observaciones', fontweight='bold')\n",
    "    axes[1].set_title('Tamaño de Grupos', fontweight='bold')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/11_equidad_area.png', dpi=300, bbox_inches='tight')\n",
    "  \n",
    "    plt.close()\n",
    "    print(f\"11_equidad_area.png\")\n",
    "\n",
    "# 2. Mapa de calor por departamento\n",
    "if 'departamento' in resultados_equidad:\n",
    "    # Preparar datos\n",
    "    dept_data = []\n",
    "    for dept, metricas in resultados_equidad['departamento'].items():\n",
    "        dept_data.append({\n",
    "            'Departamento': dept,\n",
    "            'Accuracy': metricas['accuracy'],\n",
    "            'ROC-AUC': metricas['roc_auc'],\n",
    "            'Precision': metricas['precision'],\n",
    "            'Recall': metricas['recall'],\n",
    "            'N': metricas['n']\n",
    "        })\n",
    "    \n",
    "    df_dept = pd.DataFrame(dept_data).sort_values('N', ascending=False).head(15)\n",
    "    \n",
    "    # Heatmap\n",
    "    fig, ax = plt.subplots(figsize=(12, 10))\n",
    "    \n",
    "    data_heatmap = df_dept[['Accuracy', 'ROC-AUC', 'Precision', 'Recall']].T\n",
    "    \n",
    "    sns.heatmap(data_heatmap, annot=True, fmt='.3f', cmap='RdYlGn', \n",
    "                xticklabels=df_dept['Departamento'], \n",
    "                yticklabels=['Accuracy', 'ROC-AUC', 'Precision', 'Recall'],\n",
    "                vmin=0.5, vmax=1.0, ax=ax, cbar_kws={'label': 'Valor Métrica'})\n",
    "    \n",
    "    ax.set_title('Métricas por Departamento (Top 15)\\n', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Departamento', fontweight='bold')\n",
    "    ax.set_ylabel('Métrica', fontweight='bold')\n",
    "    \n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/12_equidad_departamentos.png', dpi=300, bbox_inches='tight')\n",
    "   \n",
    "    plt.close()\n",
    "    print(f\"12_equidad_departamentos.png\")\n",
    "\n",
    "# 3. Análisis de equidad por sector\n",
    "if 'sector' in resultados_equidad:\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "    \n",
    "    sectores = list(resultados_equidad['sector'].keys())\n",
    "    \n",
    "    # Gráfica superior: ROC-AUC por sector\n",
    "    roc_aucs = [resultados_equidad['sector'][s]['roc_auc'] for s in sectores]\n",
    "    ns = [resultados_equidad['sector'][s]['n'] for s in sectores]\n",
    "    \n",
    "    axes[0].bar(range(len(sectores)), roc_aucs, alpha=0.7, color='#9b59b6')\n",
    "    axes[0].axhline(y=metricas_global['roc_auc'], color='red', linestyle='--', \n",
    "                   label=f'Global: {metricas_global[\"roc_auc\"]:.3f}')\n",
    "    axes[0].set_xlabel('Sector', fontweight='bold')\n",
    "    axes[0].set_ylabel('ROC-AUC', fontweight='bold')\n",
    "    axes[0].set_title('ROC-AUC por Sector Económico', fontweight='bold')\n",
    "    axes[0].set_xticks(range(len(sectores)))\n",
    "    axes[0].set_xticklabels(sectores, rotation=45, ha='right')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Gráfica inferior: Tamaño de grupos\n",
    "    axes[1].bar(range(len(sectores)), ns, alpha=0.7, color='#2ecc71')\n",
    "    axes[1].set_xlabel('Sector', fontweight='bold')\n",
    "    axes[1].set_ylabel('Número de Observaciones', fontweight='bold')\n",
    "    axes[1].set_title('Tamaño de Muestra por Sector', fontweight='bold')\n",
    "    axes[1].set_xticks(range(len(sectores)))\n",
    "    axes[1].set_xticklabels(sectores, rotation=45, ha='right')\n",
    "    axes[1].grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{OUTPUT_DIR}/13_equidad_sectores.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\"13_equidad_sectores.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# GUARDAR RESULTADOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GUARDANDO ANALISIS DE EQUIDAD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Guardar resultados\n",
    "with open(f'{OUTPUT_DIR}/analisis_equidad.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'resultados': resultados_equidad,\n",
    "        'disparate_impact': disparate_impact,\n",
    "        'metricas_global': metricas_global\n",
    "    }, f)\n",
    "print(f\"analisis_equidad.pkl\")\n",
    "\n",
    "# Exportar a CSV\n",
    "for grupo, metricas_dict in resultados_equidad.items():\n",
    "    df_grupo = pd.DataFrame(metricas_dict).T\n",
    "    df_grupo.to_csv(f'{OUTPUT_DIR}/equidad_{grupo}.csv')\n",
    "    print(f\"equidad_{grupo}.csv\")\n",
    "\n",
    "# =============================================================================\n",
    "# RESUMEN\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN ANALISIS DE EQUIDAD\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "Métricas Globales:\n",
    "  Accuracy: {metricas_global['accuracy']:.4f}\n",
    "  ROC-AUC: {metricas_global['roc_auc']:.4f}\n",
    "\n",
    "Disparate Impact:\n",
    "\"\"\")\n",
    "\n",
    "for grupo, di in disparate_impact.items():\n",
    "    status = \"DISPARIDAD\" if di < 0.8 else \"Aceptable\"\n",
    "    print(f\"  {grupo}: {di:.3f} {status}\")\n",
    "\n",
    "print(f\"\"\"\n",
    "Gráficas generadas:\n",
    "  - 11_equidad_area.png (urbano vs rural)\n",
    "  - 12_equidad_departamentos.png (mapa de calor)\n",
    "  - 13_equidad_sectores.png (por sector económico)\n",
    "\n",
    "Archivos CSV:\n",
    "  - equidad_area.csv\n",
    "  - equidad_departamento.csv\n",
    "  - equidad_sector.csv\n",
    "\n",
    "ANALISIS DE EQUIDAD COMPLETADO\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb3cbe-3a9e-47bb-baba-e6a037ebcc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
