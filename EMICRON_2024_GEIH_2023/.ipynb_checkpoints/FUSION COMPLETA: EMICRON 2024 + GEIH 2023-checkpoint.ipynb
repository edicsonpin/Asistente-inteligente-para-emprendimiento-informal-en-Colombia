{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0594086e-a50c-44b9-9d33-250fc1a7ea05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ruta actual: /Users/edicsonpin/Documents/maestria/TFM/borrador/EMICRON_2024_GEIH_2023\n",
      "================================================================================\n",
      "FUSION EMICRON 2024 + GEIH 2023\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PASO 1: FUSIONANDO MODULOS EMICRON\n",
      "================================================================================\n",
      "\n",
      "[1/9] Cargando módulos EMICRON...\n",
      "   identificacion: (68702, 28)\n",
      "   caracteristicas: (68702, 30)\n",
      "   ventas: (68702, 92)\n",
      "   costos: (68702, 93)\n",
      "   inclusion: (68702, 57)\n",
      "   personal: (12878, 15)\n",
      "   emprendimiento: (68702, 19)\n",
      "   tic: (68702, 47)\n",
      "   factores: (68702, 10)\n",
      "\n",
      "[2/9] Fusionando por id_micronegocio...\n",
      "   + caracteristicas: 68,702 -> 68,702\n",
      "   + ventas: 68,702 -> 68,702\n",
      "   + costos: 68,702 -> 68,702\n",
      "   + inclusion: 68,702 -> 68,702\n",
      "   + personal: 68,702 -> 68,702\n",
      "   + emprendimiento: 68,702 -> 68,702\n",
      "   + tic: 68,702 -> 68,702\n",
      "   + factores: 68,702 -> 68,702\n",
      "\n",
      "   EMICRON fusionado: (68702, 383)\n",
      "\n",
      "================================================================================\n",
      "PASO 2: CARGANDO CONTEXTO GEIH\n",
      "================================================================================\n",
      "\n",
      "Contexto GEIH cargado: (227, 5)\n",
      "  Columnas: ['codigo_departamento', 'sector_economico', 'ingreso_mediano', 'ingreso_promedio', 'num_emprendedores']\n",
      "  Combinaciones dept-sector: 227\n",
      "\n",
      "================================================================================\n",
      "PASO 3: FUSION EMICRON + GEIH\n",
      "================================================================================\n",
      "\n",
      "[3/9] Preparando fusión...\n",
      "  EMICRON tiene 'codigo_departamento': True\n",
      "  EMICRON tiene 'sector_economico': True\n",
      "  GEIH tiene 'codigo_departamento': True\n",
      "  GEIH tiene 'sector_economico': True\n",
      "\n",
      "[4/9] Ejecutando fusión...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on float64 and object columns for key 'sector_economico'. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 124\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[4/9] Ejecutando fusión...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    122\u001b[0m antes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(emicron)\n\u001b[0;32m--> 124\u001b[0m df_final \u001b[38;5;241m=\u001b[39m emicron\u001b[38;5;241m.\u001b[39mmerge(\n\u001b[1;32m    125\u001b[0m     contexto_geih,\n\u001b[1;32m    126\u001b[0m     on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcodigo_departamento\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msector_economico\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m    127\u001b[0m     how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    128\u001b[0m     suffixes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_geih\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    129\u001b[0m )\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Antes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mantes\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m micronegocios\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m   Después: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(df_final)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m micronegocios\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/frame.py:10859\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10840\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m  10841\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m  10842\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10855\u001b[0m     validate: MergeValidate \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m  10856\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m  10857\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[0;32m> 10859\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m merge(\n\u001b[1;32m  10860\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10861\u001b[0m         right,\n\u001b[1;32m  10862\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[1;32m  10863\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[1;32m  10864\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[1;32m  10865\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[1;32m  10866\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[1;32m  10867\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[1;32m  10868\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m  10869\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[1;32m  10870\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m  10871\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[1;32m  10872\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m  10873\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/merge.py:170\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _cross_merge(\n\u001b[1;32m    156\u001b[0m         left_df,\n\u001b[1;32m    157\u001b[0m         right_df,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m         copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m    168\u001b[0m     )\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 170\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    171\u001b[0m         left_df,\n\u001b[1;32m    172\u001b[0m         right_df,\n\u001b[1;32m    173\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[1;32m    174\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[1;32m    175\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[1;32m    176\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[1;32m    177\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[1;32m    178\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[1;32m    179\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    180\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[1;32m    181\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[1;32m    182\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/merge.py:807\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_tolerance(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys)\n\u001b[1;32m    805\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    806\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[0;32m--> 807\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n\u001b[1;32m    809\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[1;32m    810\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[1;32m    811\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[1;32m    812\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/pandas/core/reshape/merge.py:1509\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1503\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[1;32m   1505\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1506\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   1507\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[1;32m   1508\u001b[0m     ):\n\u001b[0;32m-> 1509\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[1;32m   1512\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[0;31mValueError\u001b[0m: You are trying to merge on float64 and object columns for key 'sector_economico'. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "FUSION COMPLETA: EMICRON 2024 + GEIH 2023\n",
    "Dataset maestro para modelo ML\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "ruta_actual = os.getcwd()\n",
    "print(\"Ruta actual:\", ruta_actual)\n",
    "print(\"=\"*80)\n",
    "print(\"FUSION EMICRON 2024 + GEIH 2023\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURACION\n",
    "# =============================================================================\n",
    "\n",
    "OUTPUT_DIR = 'FUSION EMICRON 2024 + GEIH 2023'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "EMICRON_DIR = 'EMICRON_2024/LIMPIOS'\n",
    "GEIH_DIR = 'GEIH_2023/LIMPIOS'\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 1: CARGAR Y FUSIONAR MODULOS EMICRON\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 1: FUSIONANDO MODULOS EMICRON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n[1/9] Cargando módulos EMICRON...\")\n",
    "\n",
    "# Cargar cada módulo\n",
    "modulos = {\n",
    "    'identificacion': 'identificacion_limpio.csv',\n",
    "    'caracteristicas': 'caracteristicas_limpio.csv',\n",
    "    'ventas': 'ventas_ingresos_limpio.csv',\n",
    "    'costos': 'costos_gastos_activos_limpio.csv',\n",
    "    'inclusion': 'inclusion_financiera_limpio.csv',\n",
    "    'personal': 'personal_ocupado_agregado.csv',\n",
    "    'emprendimiento': 'emprendimiento_limpio.csv',\n",
    "    'tic': 'tic_limpio.csv',\n",
    "    'factores': 'factores_departamentales_limpio.csv'\n",
    "}\n",
    "\n",
    "dfs_emicron = {}\n",
    "\n",
    "for nombre, archivo in modulos.items():\n",
    "    ruta = f'{EMICRON_DIR}/{archivo}'\n",
    "    \n",
    "    if os.path.exists(ruta):\n",
    "        df = pd.read_csv(ruta)\n",
    "        dfs_emicron[nombre] = df\n",
    "        print(f\"   {nombre}: {df.shape}\")\n",
    "    else:\n",
    "        print(f\"   {nombre}: NO ENCONTRADO ({ruta})\")\n",
    "\n",
    "# Fusionar por id_micronegocio\n",
    "print(\"\\n[2/9] Fusionando por id_micronegocio...\")\n",
    "\n",
    "if 'identificacion' in dfs_emicron:\n",
    "    emicron = dfs_emicron['identificacion'].copy()\n",
    "    \n",
    "    for nombre, df in dfs_emicron.items():\n",
    "        if nombre != 'identificacion' and 'id_micronegocio' in df.columns:\n",
    "            antes = len(emicron)\n",
    "            emicron = emicron.merge(df, on='id_micronegocio', how='left', suffixes=('', f'_{nombre}'))\n",
    "            print(f\"   + {nombre}: {antes:,} -> {len(emicron):,}\")\n",
    "    \n",
    "    print(f\"\\n   EMICRON fusionado: {emicron.shape}\")\n",
    "else:\n",
    "    print(\"   ERROR: No se encontró módulo de identificación\")\n",
    "    emicron = None\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 2: CARGAR CONTEXTO GEIH\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 2: CARGANDO CONTEXTO GEIH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "contexto_file = f'{GEIH_DIR}/contexto_laboral_dept_sector.csv'\n",
    "\n",
    "if os.path.exists(contexto_file):\n",
    "    contexto_geih = pd.read_csv(contexto_file)\n",
    "    print(f\"\\nContexto GEIH cargado: {contexto_geih.shape}\")\n",
    "    print(f\"  Columnas: {list(contexto_geih.columns)}\")\n",
    "    print(f\"  Combinaciones dept-sector: {len(contexto_geih):,}\")\n",
    "else:\n",
    "    print(f\"ERROR: No se encontró {contexto_file}\")\n",
    "    contexto_geih = None\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 3: FUSION EMICRON + GEIH\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 3: FUSION EMICRON + GEIH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if emicron is not None and contexto_geih is not None:\n",
    "    print(\"\\n[3/9] Preparando fusión...\")\n",
    "    \n",
    "    # Verificar columnas clave\n",
    "    print(f\"  EMICRON tiene 'codigo_departamento': {'codigo_departamento' in emicron.columns}\")\n",
    "    print(f\"  EMICRON tiene 'sector_economico': {'sector_economico' in emicron.columns}\")\n",
    "    print(f\"  GEIH tiene 'codigo_departamento': {'codigo_departamento' in contexto_geih.columns}\")\n",
    "    print(f\"  GEIH tiene 'sector_economico': {'sector_economico' in contexto_geih.columns}\")\n",
    "    \n",
    "    # Fusionar\n",
    "    print(\"\\n[4/9] Ejecutando fusión...\")\n",
    "    antes = len(emicron)\n",
    "    \n",
    "    df_final = emicron.merge(\n",
    "        contexto_geih,\n",
    "        on=['codigo_departamento', 'sector_economico'],\n",
    "        how='left',\n",
    "        suffixes=('', '_geih')\n",
    "    )\n",
    "    \n",
    "    print(f\"   Antes: {antes:,} micronegocios\")\n",
    "    print(f\"   Después: {len(df_final):,} micronegocios\")\n",
    "    print(f\"   Columnas totales: {len(df_final.columns)}\")\n",
    "    \n",
    "    # Verificar match\n",
    "    matched = df_final['ingreso_mediano'].notna().sum() if 'ingreso_mediano' in df_final.columns else 0\n",
    "    print(f\"   Micronegocios con contexto GEIH: {matched:,} ({matched/len(df_final)*100:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 4: CREAR VARIABLE OBJETIVO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 4: CREAR VARIABLE OBJETIVO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_final' in locals():\n",
    "    print(\"\\n[5/9] Definiendo variable objetivo...\")\n",
    "    \n",
    "    # OPCION A: Éxito basado en ingresos relativos al sector\n",
    "    if 'ingresos_totales_declarados' in df_final.columns and 'ingreso_mediano' in df_final.columns:\n",
    "        # Convertir a numérico\n",
    "        df_final['ingresos_totales_declarados'] = pd.to_numeric(df_final['ingresos_totales_declarados'], errors='coerce')\n",
    "        df_final['ingreso_mediano'] = pd.to_numeric(df_final['ingreso_mediano'], errors='coerce')\n",
    "        \n",
    "        # Éxito = ingresos por encima de la mediana del sector en el departamento\n",
    "        df_final['exito_ingresos'] = (\n",
    "            df_final['ingresos_totales_declarados'] > df_final['ingreso_mediano']\n",
    "        ).astype(int)\n",
    "        \n",
    "        print(f\"   Variable objetivo 'exito_ingresos' creada\")\n",
    "        print(f\"   Distribución:\")\n",
    "        print(df_final['exito_ingresos'].value_counts())\n",
    "        print(f\"   Balance: {df_final['exito_ingresos'].mean()*100:.1f}% exitosos\")\n",
    "    \n",
    "    # OPCION B: Índice compuesto de éxito\n",
    "    componentes = []\n",
    "    pesos = []\n",
    "    \n",
    "    # Componente 1: Ingresos (40%)\n",
    "    if 'ingresos_totales_declarados' in df_final.columns:\n",
    "        df_final['ingresos_norm'] = (df_final['ingresos_totales_declarados'] - df_final['ingresos_totales_declarados'].min()) / \\\n",
    "                                     (df_final['ingresos_totales_declarados'].max() - df_final['ingresos_totales_declarados'].min())\n",
    "        componentes.append(df_final['ingresos_norm'])\n",
    "        pesos.append(0.4)\n",
    "    \n",
    "    # Componente 2: Antigüedad (20%)\n",
    "    if 'antiguedad_negocio' in df_final.columns:\n",
    "        df_final['antiguedad_norm'] = (df_final['antiguedad_negocio'] - df_final['antiguedad_negocio'].min()) / \\\n",
    "                                       (df_final['antiguedad_negocio'].max() - df_final['antiguedad_negocio'].min())\n",
    "        componentes.append(df_final['antiguedad_norm'])\n",
    "        pesos.append(0.2)\n",
    "    \n",
    "    # Componente 3: Rentabilidad (20%)\n",
    "    if 'margen_bruto' in df_final.columns:\n",
    "        df_final['margen_norm'] = (df_final['margen_bruto'] - df_final['margen_bruto'].min()) / \\\n",
    "                                   (df_final['margen_bruto'].max() - df_final['margen_bruto'].min())\n",
    "        componentes.append(df_final['margen_norm'])\n",
    "        pesos.append(0.2)\n",
    "    \n",
    "    # Componente 4: Madurez digital (20%)\n",
    "    if 'indice_madurez_digital' in df_final.columns:\n",
    "        df_final['digital_norm'] = df_final['indice_madurez_digital'] / 100\n",
    "        componentes.append(df_final['digital_norm'])\n",
    "        pesos.append(0.2)\n",
    "    \n",
    "    # Calcular índice compuesto si hay componentes\n",
    "    if componentes:\n",
    "        # Normalizar pesos para que sumen 1\n",
    "        pesos_norm = np.array(pesos) / sum(pesos)\n",
    "        \n",
    "        # Calcular índice\n",
    "        indice = sum(c.fillna(0) * p for c, p in zip(componentes, pesos_norm))\n",
    "        df_final['indice_exito'] = indice * 100\n",
    "        \n",
    "        # Variable binaria: éxito si índice > 50\n",
    "        df_final['exito_compuesto'] = (df_final['indice_exito'] > 50).astype(int)\n",
    "        \n",
    "        print(f\"\\n   Variable objetivo 'exito_compuesto' creada\")\n",
    "        print(f\"   Componentes: {len(componentes)}\")\n",
    "        print(f\"   Distribución:\")\n",
    "        print(df_final['exito_compuesto'].value_counts())\n",
    "        print(f\"   Balance: {df_final['exito_compuesto'].mean()*100:.1f}% exitosos\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 5: LIMPIEZA FINAL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 5: LIMPIEZA FINAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_final' in locals():\n",
    "    print(\"\\n[6/9] Limpieza de dataset final...\")\n",
    "    \n",
    "    # Eliminar duplicados\n",
    "    antes = len(df_final)\n",
    "    df_final = df_final.drop_duplicates(subset=['id_micronegocio'])\n",
    "    print(f\"   Duplicados eliminados: {antes - len(df_final):,}\")\n",
    "    \n",
    "    # Reporte de valores perdidos\n",
    "    missing_total = df_final.isnull().sum().sum()\n",
    "    print(f\"   Valores perdidos totales: {missing_total:,}\")\n",
    "    \n",
    "    # Top 10 columnas con más missing\n",
    "    missing_cols = df_final.isnull().sum().sort_values(ascending=False).head(10)\n",
    "    if missing_cols.sum() > 0:\n",
    "        print(f\"\\n   Top 10 columnas con missing:\")\n",
    "        for col, count in missing_cols.items():\n",
    "            pct = count / len(df_final) * 100\n",
    "            print(f\"     {col}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 6: SELECCIONAR COLUMNAS RELEVANTES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 6: SELECCION DE FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_final' in locals():\n",
    "    print(\"\\n[7/9] Identificando features relevantes...\")\n",
    "    \n",
    "    # Columnas a MANTENER (features para ML)\n",
    "    cols_relevantes = []\n",
    "    \n",
    "    # Identificadores\n",
    "    cols_relevantes.extend(['id_micronegocio'])\n",
    "    \n",
    "    # Variables objetivo\n",
    "    if 'exito_ingresos' in df_final.columns:\n",
    "        cols_relevantes.append('exito_ingresos')\n",
    "    if 'exito_compuesto' in df_final.columns:\n",
    "        cols_relevantes.append('exito_compuesto')\n",
    "    if 'indice_exito' in df_final.columns:\n",
    "        cols_relevantes.append('indice_exito')\n",
    "    \n",
    "    # Ubicación\n",
    "    for col in ['codigo_departamento', 'nombre_departamento', 'area_urbana', 'area']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # Características del negocio\n",
    "    for col in ['sector_economico', 'antiguedad_negocio', 'tipo_establecimiento', \n",
    "                'formalidad', 'num_trabajadores']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # Variables económicas\n",
    "    for col in ['ingresos_totales_declarados', 'costos_totales', 'margen_bruto',\n",
    "                'ratio_costos_ventas', 'activos_totales', 'intensidad_capital']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # Inclusión financiera\n",
    "    for col in ['num_productos_financieros', 'acceso_credito', 'usa_banca_digital',\n",
    "                'indice_inclusion_financiera']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # Emprendimiento\n",
    "    for col in ['tipo_emprendimiento', 'experiencia_previa', 'motivo_principal']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # TIC\n",
    "    for col in ['acceso_internet', 'num_dispositivos', 'num_canales_digitales',\n",
    "                'indice_madurez_digital', 'presencia_digital']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # Contexto GEIH\n",
    "    for col in ['ingreso_mediano', 'ingreso_promedio', 'num_emprendedores']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # Filtrar solo las que existen\n",
    "    cols_finales = [c for c in cols_relevantes if c in df_final.columns]\n",
    "    \n",
    "    # Agregar columnas numéricas adicionales que no estén en la lista\n",
    "    numericas = df_final.select_dtypes(include=[np.number]).columns\n",
    "    for col in numericas:\n",
    "        if col not in cols_finales and not col.startswith('Unnamed'):\n",
    "            cols_finales.append(col)\n",
    "    \n",
    "    # Dataset final reducido\n",
    "    df_ml = df_final[cols_finales].copy()\n",
    "    \n",
    "    print(f\"   Columnas seleccionadas: {len(cols_finales)}\")\n",
    "    print(f\"   Dataset ML: {df_ml.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 7: GUARDAR DATASETS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 7: GUARDANDO DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_final' in locals():\n",
    "    print(\"\\n[8/9] Guardando archivos...\")\n",
    "    \n",
    "    # Dataset completo\n",
    "    df_final.to_csv(f'{OUTPUT_DIR}/dataset_maestro_completo.csv', index=False, encoding='utf-8-sig')\n",
    "    size_completo = os.path.getsize(f'{OUTPUT_DIR}/dataset_maestro_completo.csv') / (1024*1024)\n",
    "    print(f\"   dataset_maestro_completo.csv: {df_final.shape} ({size_completo:.1f} MB)\")\n",
    "    \n",
    "    # Dataset para ML (reducido)\n",
    "    if 'df_ml' in locals():\n",
    "        df_ml.to_csv(f'{OUTPUT_DIR}/dataset_ml.csv', index=False, encoding='utf-8-sig')\n",
    "        size_ml = os.path.getsize(f'{OUTPUT_DIR}/dataset_ml.csv') / (1024*1024)\n",
    "        print(f\"   dataset_ml.csv: {df_ml.shape} ({size_ml:.1f} MB)\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 8: ESTADISTICAS Y VISUALIZACIONES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 8: ESTADISTICAS DESCRIPTIVAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_ml' in locals():\n",
    "    print(\"\\n[9/9] Generando estadísticas...\")\n",
    "    \n",
    "    # Resumen de variable objetivo\n",
    "    if 'exito_ingresos' in df_ml.columns:\n",
    "        print(f\"\\nVariable objetivo 'exito_ingresos':\")\n",
    "        print(df_ml['exito_ingresos'].value_counts())\n",
    "        print(f\"  Balance: {df_ml['exito_ingresos'].mean()*100:.1f}% exitosos\")\n",
    "    \n",
    "    if 'exito_compuesto' in df_ml.columns:\n",
    "        print(f\"\\nVariable objetivo 'exito_compuesto':\")\n",
    "        print(df_ml['exito_compuesto'].value_counts())\n",
    "        print(f\"  Balance: {df_ml['exito_compuesto'].mean()*100:.1f}% exitosos\")\n",
    "    \n",
    "    # Tipos de datos\n",
    "    print(f\"\\nTipos de datos:\")\n",
    "    print(df_ml.dtypes.value_counts())\n",
    "    \n",
    "    # Missing por columna\n",
    "    missing_pct = (df_ml.isnull().sum() / len(df_ml) * 100).sort_values(ascending=False)\n",
    "    missing_importantes = missing_pct[missing_pct > 10]\n",
    "    if len(missing_importantes) > 0:\n",
    "        print(f\"\\nColumnas con >10% missing:\")\n",
    "        for col, pct in missing_importantes.items():\n",
    "            print(f\"  {col}: {pct:.1f}%\")\n",
    "    \n",
    "    # Estadísticas básicas de features numéricas clave\n",
    "    if 'ingresos_totales_declarados' in df_ml.columns:\n",
    "        print(f\"\\nIngresos totales:\")\n",
    "        print(f\"  Mediana: ${df_ml['ingresos_totales_declarados'].median():,.0f}\")\n",
    "        print(f\"  Promedio: ${df_ml['ingresos_totales_declarados'].mean():,.0f}\")\n",
    "    \n",
    "    if 'indice_madurez_digital' in df_ml.columns:\n",
    "        print(f\"\\nMadurez digital:\")\n",
    "        print(f\"  Mediana: {df_ml['indice_madurez_digital'].median():.1f}/100\")\n",
    "        print(f\"  Promedio: {df_ml['indice_madurez_digital'].mean():.1f}/100\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 9: VISUALIZACIONES RAPIDAS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 9: VISUALIZACIONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_ml' in locals():\n",
    "    print(\"\\nGenerando gráficos rápidos...\")\n",
    "    \n",
    "    # Configurar estilo\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    \n",
    "    # Figura 1: Distribución variable objetivo\n",
    "    if 'exito_ingresos' in df_ml.columns:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "        df_ml['exito_ingresos'].value_counts().plot(kind='bar', ax=ax, color=['#e74c3c', '#27ae60'])\n",
    "        ax.set_title('Distribución Variable Objetivo: Éxito en Ingresos', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Clase', fontweight='bold')\n",
    "        ax.set_ylabel('Frecuencia', fontweight='bold')\n",
    "        ax.set_xticklabels(['Fracaso (0)', 'Éxito (1)'], rotation=0)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/01_distribucion_objetivo.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"    01_distribucion_objetivo.png\")\n",
    "    \n",
    "    # Figura 2: Éxito por sector\n",
    "    if 'exito_ingresos' in df_ml.columns and 'sector_economico' in df_ml.columns:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(12, 6))\n",
    "        exito_sector = df_ml.groupby('sector_economico')['exito_ingresos'].agg(['mean', 'count'])\n",
    "        exito_sector = exito_sector[exito_sector['count'] >= 50].sort_values('mean', ascending=False)\n",
    "        exito_sector['mean'].plot(kind='barh', ax=ax, color='#3498db')\n",
    "        ax.set_title('Tasa de Éxito por Sector Económico', fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Tasa de Éxito', fontweight='bold')\n",
    "        ax.set_ylabel('Sector', fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{OUTPUT_DIR}/02_exito_por_sector.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"    02_exito_por_sector.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# RESUMEN FINAL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN FINAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_ml' in locals():\n",
    "    print(f\"\\n FUSION COMPLETADA CON EXITO\")\n",
    "    print(f\"\\nDatasets generados en '{OUTPUT_DIR}/':\")\n",
    "    print(f\"  1. dataset_maestro_completo.csv - Todas las columnas\")\n",
    "    print(f\"  2. dataset_ml.csv - Columnas seleccionadas para ML\")\n",
    "    print(f\"\\nDimensiones finales:\")\n",
    "    print(f\"  Micronegocios: {len(df_ml):,}\")\n",
    "    print(f\"  Features: {len(df_ml.columns)}\")\n",
    "    print(f\"  Variable objetivo: {'exito_ingresos' if 'exito_ingresos' in df_ml.columns else 'exito_compuesto'}\")\n",
    "    \n",
    "    if 'exito_ingresos' in df_ml.columns:\n",
    "        balance = df_ml['exito_ingresos'].mean() * 100\n",
    "        print(f\"  Balance de clases: {balance:.1f}% / {100-balance:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"PROXIMO PASO: Ejecutar modelo baseline\")\n",
    "    print(\"  python 02_modelo_baseline.py\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"\\n✗ ERROR EN LA FUSION\")\n",
    "    print(\"Revisa que todos los archivos existan en las rutas correctas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1fb6cfb-f6b6-4e9a-8106-115fd39c7a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ La carpeta existe!\n",
      "Contenido encontrado:\n",
      " - eda_02_sector_economico.png\n",
      " - ventas_ingresos_limpio.csv\n",
      " - eda_emprendimiento_04_ingresos.png\n",
      " - eda_ventas_01_histogramas_log.png\n",
      " - eda_tic_03_ventas.png\n",
      " - eda_01_boxplots.png\n",
      " - eda_inclusion_05_resiliencia.png\n",
      " - eda_inclusion_01_productos.png\n",
      " - emprendimiento_limpio.csv\n",
      " - eda_caract_01_formal_informal.png\n",
      " - eda_emprendimiento_01_motivacion.png\n",
      " - eda_04_mapa_coropletico.png\n",
      " - tic_limpio.csv\n",
      " - eda_personal_03_genero.png\n",
      " - eda_02_ratios.png\n",
      " - eda_tic_05_integracion.png\n",
      " - eda_emprendimiento_03_continuidad.png\n",
      " - eda_emprendimiento_05_resumen.png\n",
      " - eda_inclusion_03_educacion.png\n",
      " - eda_personal_04_formalidad.png\n",
      " - eda_personal_01_distribucion.png\n",
      " - eda_tic_01_acceso.png\n",
      " - eda_caract_05_antiguedad_tamano.png\n",
      " - eda_01_departamentos.png\n",
      " - eda_tic_04_madurez.png\n",
      " - eda_ventas_04_estacionalidad_pago.png\n",
      " - eda_caract_04_apoyo_gestion.png\n",
      " - caracteristicas_limpio.csv\n",
      " - eda_03_activos.png\n",
      " - eda_04_estructura.png\n",
      " - eda_personal_05_calidad.png\n",
      " - eda_ventas_03_ventas_departamento.png\n",
      " - eda_inclusion_04_indice.png\n",
      " - eda_03_antiguedad_negocio.png\n",
      " - personal_ocupado_agregado.csv\n",
      " - inclusion_financiera_limpio.csv\n",
      " - .ipynb_checkpoints\n",
      " - eda_caract_02_tipo_establecimiento.png\n",
      " - eda_05_matriz_correlacion.png\n",
      " - factores_departamentales_limpio.csv\n",
      " - eda_05_eficiencia.png\n",
      " - eda_personal_02_vinculo.png\n",
      " - eda_caract_03_sector_formalidad.png\n",
      " - costos_gastos_activos_limpio.csv\n",
      " - identificacion_limpio.csv\n",
      " - eda_emprendimiento_02_experiencia.png\n",
      " - eda_ventas_05_intensidad_crecimiento.png\n",
      " - eda_tic_02_herramientas.png\n",
      " - eda_inclusion_02_credito.png\n",
      " - personal_ocupado_detalle.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Definimos la ruta tal cual la tienes\n",
    "ruta_objetivo = Path(\"EMICRON_2024/LIMPIOS\")\n",
    "\n",
    "if ruta_objetivo.exists():\n",
    "    print(f\"✅ La carpeta existe!\")\n",
    "    print(\"Contenido encontrado:\")\n",
    "    for archivo in os.listdir(ruta_objetivo):\n",
    "        print(f\" - {archivo}\")\n",
    "else:\n",
    "    print(f\"❌ La ruta no existe. Ruta intentada: {ruta_objetivo.absolute()}\")\n",
    "    # Verifiquemos qué hay en el nivel anterior\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "178f1f31-0cb4-46a6-befd-86af4351f5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FUSION EMICRON 2024 + GEIH 2023\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "PASO 1: FUSIONANDO MODULOS EMICRON\n",
      "================================================================================\n",
      "\n",
      "[1/9] Cargando módulos EMICRON...\n",
      "   identificacion: (68702, 28)\n",
      "   caracteristicas: (68702, 30)\n",
      "   ventas: (68702, 92)\n",
      "   costos: (68702, 93)\n",
      "   inclusion: (68702, 57)\n",
      "   personal: (12878, 15)\n",
      "   emprendimiento: (68702, 19)\n",
      "   tic: (68702, 47)\n",
      "   factores: (68702, 10)\n",
      "\n",
      "[2/9] Fusionando por id_micronegocio...\n",
      "   + caracteristicas: 68,702 -> 68,702\n",
      "   + ventas: 68,702 -> 68,702\n",
      "   + costos: 68,702 -> 68,702\n",
      "   + inclusion: 68,702 -> 68,702\n",
      "   + personal: 68,702 -> 68,702\n",
      "   + emprendimiento: 68,702 -> 68,702\n",
      "   + tic: 68,702 -> 68,702\n",
      "   + factores: 68,702 -> 68,702\n",
      "\n",
      "   EMICRON fusionado: (68702, 383)\n",
      "\n",
      "================================================================================\n",
      "PASO 2: CARGANDO CONTEXTO GEIH\n",
      "================================================================================\n",
      "\n",
      "Contexto GEIH cargado: (227, 5)\n",
      "  Columnas: ['codigo_departamento', 'sector_economico', 'ingreso_mediano', 'ingreso_promedio', 'num_emprendedores']\n",
      "  Combinaciones dept-sector: 227\n",
      "\n",
      "================================================================================\n",
      "PASO 3: FUSION EMICRON + GEIH\n",
      "================================================================================\n",
      "\n",
      "[3/9] Preparando fusión...\n",
      "  EMICRON tiene 'codigo_departamento': True\n",
      "  EMICRON tiene 'sector_economico': True\n",
      "  GEIH tiene 'codigo_departamento': True\n",
      "  GEIH tiene 'sector_economico': True\n",
      "\n",
      "[4/9] Ejecutando fusión...\n",
      "   Estandarizando tipos de datos...\n",
      "   EMICRON - codigo_departamento: Int64\n",
      "   EMICRON - sector_economico: object\n",
      "   GEIH - codigo_departamento: Int64\n",
      "   GEIH - sector_economico: object\n",
      "   Antes: 68,702 micronegocios\n",
      "   Después: 68,702 micronegocios\n",
      "   Columnas totales: 386\n",
      "   Micronegocios con contexto GEIH: 0 (0.0%)\n",
      "\n",
      "================================================================================\n",
      "PASO 4: CREAR VARIABLE OBJETIVO\n",
      "================================================================================\n",
      "\n",
      "[5/9] Definiendo variable objetivo...\n",
      "   Variable objetivo 'exito_ingresos' creada\n",
      "   Distribución:\n",
      "exito_ingresos\n",
      "0    68702\n",
      "Name: count, dtype: int64\n",
      "   Balance: 0.0% exitosos\n",
      "\n",
      "   Variable objetivo 'exito_compuesto' creada\n",
      "   Componentes: 3\n",
      "   Distribución:\n",
      "exito_compuesto\n",
      "0    51601\n",
      "1    17101\n",
      "Name: count, dtype: int64\n",
      "   Balance: 24.9% exitosos\n",
      "\n",
      "================================================================================\n",
      "PASO 5: LIMPIEZA FINAL\n",
      "================================================================================\n",
      "\n",
      "[6/9] Limpieza de dataset final...\n",
      "   Duplicados eliminados: 0\n",
      "   Valores perdidos totales: 1,928,377\n",
      "\n",
      "   Top 10 columnas con missing:\n",
      "     indice_contexto_favorable: 68,702 (100.0%)\n",
      "     num_emprendedores: 68,702 (100.0%)\n",
      "     ingreso_mediano: 68,702 (100.0%)\n",
      "     ingreso_promedio: 68,702 (100.0%)\n",
      "     mes_cos: 68,702 (100.0%)\n",
      "     mes_num: 68,702 (100.0%)\n",
      "     mes_sin: 68,702 (100.0%)\n",
      "     otros_costos: 68,696 (100.0%)\n",
      "     otros_gastos: 68,696 (100.0%)\n",
      "     otro_credito: 68,667 (99.9%)\n",
      "\n",
      "================================================================================\n",
      "PASO 6: SELECCION DE FEATURES\n",
      "================================================================================\n",
      "\n",
      "[7/9] Identificando features relevantes...\n",
      "   Columnas seleccionadas: 377\n",
      "   Dataset ML: (68702, 377)\n",
      "\n",
      "================================================================================\n",
      "PASO 7: GUARDANDO DATASETS\n",
      "================================================================================\n",
      "\n",
      "[8/9] Guardando archivos...\n",
      "   dataset_maestro_completo.csv: (68702, 392) (126.1 MB)\n",
      "   dataset_ml.csv: (68702, 377) (116.2 MB)\n",
      "\n",
      "================================================================================\n",
      "PASO 8: ESTADISTICAS DESCRIPTIVAS\n",
      "================================================================================\n",
      "\n",
      "[9/9] Generando estadísticas...\n",
      "\n",
      "Variable objetivo 'exito_ingresos':\n",
      "exito_ingresos\n",
      "0    68702\n",
      "Name: count, dtype: int64\n",
      "  Balance: 0.0% exitosos\n",
      "\n",
      "Variable objetivo 'exito_compuesto':\n",
      "exito_compuesto\n",
      "0    51601\n",
      "1    17101\n",
      "Name: count, dtype: int64\n",
      "  Balance: 24.9% exitosos\n",
      "\n",
      "Tipos de datos:\n",
      "float64    202\n",
      "int64      171\n",
      "object       3\n",
      "Int64        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Columnas con >10% missing:\n",
      "  mes_cos: 100.0%\n",
      "  ingreso_mediano: 100.0%\n",
      "  mes_sin: 100.0%\n",
      "  indice_contexto_favorable: 100.0%\n",
      "  mes_num: 100.0%\n",
      "  num_emprendedores: 100.0%\n",
      "  ingreso_promedio: 100.0%\n",
      "  otros_gastos: 100.0%\n",
      "  otros_costos: 100.0%\n",
      "  otro_credito: 99.9%\n",
      "  variacion_anual_ventas_wins: 87.0%\n",
      "  variacion_anual_ventas_scaled: 87.0%\n",
      "  variacion_anual_ventas: 87.0%\n",
      "  expectativa_ventas: 86.4%\n",
      "  numero_trabajadores: 81.3%\n",
      "  formalidad_laboral_personal: 81.3%\n",
      "  tiene_seguridad_social: 81.3%\n",
      "  trabajadores_mujeres: 81.3%\n",
      "  trabajadores_familiares: 81.3%\n",
      "  prop_familiares: 81.3%\n",
      "  prop_mujeres: 81.3%\n",
      "  prop_remunerados: 81.3%\n",
      "  trabajadores_no_familiares: 81.3%\n",
      "  trabajadores_permanentes: 81.3%\n",
      "  trabajadores_temporales: 81.3%\n",
      "  trabajadores_remunerados: 81.3%\n",
      "  trabajadores_no_remunerados: 81.3%\n",
      "  indice_calidad_empleo: 81.3%\n",
      "  billetera_digital: 62.1%\n",
      "  variacion_mensual_ventas_scaled: 47.1%\n",
      "  variacion_mensual_ventas_wins: 47.1%\n",
      "  variacion_mensual_ventas: 47.1%\n",
      "  crecimiento_anual: 17.6%\n",
      "  ventas_total_anual: 17.6%\n",
      "  ventas_total_anual_log: 17.6%\n",
      "\n",
      "Ingresos totales:\n",
      "  Mediana: $0\n",
      "  Promedio: $1,421\n",
      "\n",
      "Madurez digital:\n",
      "  Mediana: 90.0/100\n",
      "  Promedio: 93.6/100\n",
      "\n",
      "================================================================================\n",
      "PASO 9: VISUALIZACIONES\n",
      "================================================================================\n",
      "\n",
      "Generando gráficos rápidos...\n",
      "\n",
      "================================================================================\n",
      "RESUMEN FINAL\n",
      "================================================================================\n",
      "\n",
      "✓ FUSION COMPLETADA CON EXITO\n",
      "\n",
      "Datasets generados en 'FUSION EMICRON 2024 + GEIH 2023/':\n",
      "  1. dataset_maestro_completo.csv - Todas las columnas\n",
      "  2. dataset_ml.csv - Columnas seleccionadas para ML\n",
      "\n",
      "Dimensiones finales:\n",
      "  Micronegocios: 68,702\n",
      "  Features: 377\n",
      "  Variable objetivo: exito_ingresos\n",
      "  Balance de clases: 0.0% / 100.0%\n",
      "\n",
      "================================================================================\n",
      "PROXIMO PASO: Ejecutar modelo baseline\n",
      "  python 02_modelo_baseline.py\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "FUSION COMPLETA: EMICRON 2024 + GEIH 2023\n",
    "Dataset maestro para modelo ML\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FUSION EMICRON 2024 + GEIH 2023\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# =============================================================================\n",
    "# CONFIGURACION\n",
    "# =============================================================================\n",
    "\n",
    "OUTPUT_DIR = 'FUSION EMICRON 2024 + GEIH 2023'\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "EMICRON_DIR = 'EMICRON_2024/LIMPIOS'\n",
    "GEIH_DIR = 'GEIH_2023/LIMPIOS'\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 1: CARGAR Y FUSIONAR MODULOS EMICRON\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 1: FUSIONANDO MODULOS EMICRON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n[1/9] Cargando módulos EMICRON...\")\n",
    "\n",
    "# Cargar cada módulo\n",
    "modulos = {\n",
    "    'identificacion': 'identificacion_limpio.csv',\n",
    "    'caracteristicas': 'caracteristicas_limpio.csv',\n",
    "    'ventas': 'ventas_ingresos_limpio.csv',\n",
    "    'costos': 'costos_gastos_activos_limpio.csv',\n",
    "    'inclusion': 'inclusion_financiera_limpio.csv',\n",
    "    'personal': 'personal_ocupado_agregado.csv',\n",
    "    'emprendimiento': 'emprendimiento_limpio.csv',\n",
    "    'tic': 'tic_limpio.csv',\n",
    "    'factores': 'factores_departamentales_limpio.csv'\n",
    "}\n",
    "\n",
    "dfs_emicron = {}\n",
    "\n",
    "for nombre, archivo in modulos.items():\n",
    "    ruta = f'{EMICRON_DIR}/{archivo}'\n",
    "    if os.path.exists(ruta):\n",
    "        df = pd.read_csv(ruta)\n",
    "        dfs_emicron[nombre] = df\n",
    "        print(f\"   {nombre}: {df.shape}\")\n",
    "    else:\n",
    "        print(f\"   {nombre}: NO ENCONTRADO ({ruta})\")\n",
    "\n",
    "# Fusionar por id_micronegocio\n",
    "print(\"\\n[2/9] Fusionando por id_micronegocio...\")\n",
    "\n",
    "if 'identificacion' in dfs_emicron:\n",
    "    emicron = dfs_emicron['identificacion'].copy()\n",
    "    \n",
    "    for nombre, df in dfs_emicron.items():\n",
    "        if nombre != 'identificacion' and 'id_micronegocio' in df.columns:\n",
    "            antes = len(emicron)\n",
    "            emicron = emicron.merge(df, on='id_micronegocio', how='left', suffixes=('', f'_{nombre}'))\n",
    "            print(f\"   + {nombre}: {antes:,} -> {len(emicron):,}\")\n",
    "    \n",
    "    print(f\"\\n   EMICRON fusionado: {emicron.shape}\")\n",
    "else:\n",
    "    print(\"   ERROR: No se encontró módulo de identificación\")\n",
    "    emicron = None\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 2: CARGAR CONTEXTO GEIH\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 2: CARGANDO CONTEXTO GEIH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "contexto_file = f'{GEIH_DIR}/contexto_laboral_dept_sector.csv'\n",
    "\n",
    "if os.path.exists(contexto_file):\n",
    "    contexto_geih = pd.read_csv(contexto_file)\n",
    "    print(f\"\\nContexto GEIH cargado: {contexto_geih.shape}\")\n",
    "    print(f\"  Columnas: {list(contexto_geih.columns)}\")\n",
    "    print(f\"  Combinaciones dept-sector: {len(contexto_geih):,}\")\n",
    "else:\n",
    "    print(f\"ERROR: No se encontró {contexto_file}\")\n",
    "    contexto_geih = None\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 3: FUSION EMICRON + GEIH\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 3: FUSION EMICRON + GEIH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if emicron is not None and contexto_geih is not None:\n",
    "    print(\"\\n[3/9] Preparando fusión...\")\n",
    "    \n",
    "    # Verificar columnas clave\n",
    "    print(f\"  EMICRON tiene 'codigo_departamento': {'codigo_departamento' in emicron.columns}\")\n",
    "    print(f\"  EMICRON tiene 'sector_economico': {'sector_economico' in emicron.columns}\")\n",
    "    print(f\"  GEIH tiene 'codigo_departamento': {'codigo_departamento' in contexto_geih.columns}\")\n",
    "    print(f\"  GEIH tiene 'sector_economico': {'sector_economico' in contexto_geih.columns}\")\n",
    "    \n",
    "    # Fusionar\n",
    "    print(\"\\n[4/9] Ejecutando fusión...\")\n",
    "    \n",
    "    # CORRECCION: Estandarizar tipos de datos antes del merge\n",
    "    print(\"   Estandarizando tipos de datos...\")\n",
    "    \n",
    "    # Convertir codigo_departamento a int en ambos datasets\n",
    "    if 'codigo_departamento' in emicron.columns:\n",
    "        emicron['codigo_departamento'] = pd.to_numeric(emicron['codigo_departamento'], errors='coerce').astype('Int64')\n",
    "    \n",
    "    if 'codigo_departamento' in contexto_geih.columns:\n",
    "        contexto_geih['codigo_departamento'] = pd.to_numeric(contexto_geih['codigo_departamento'], errors='coerce').astype('Int64')\n",
    "    \n",
    "    # Convertir sector_economico a string en ambos datasets\n",
    "    if 'sector_economico' in emicron.columns:\n",
    "        emicron['sector_economico'] = emicron['sector_economico'].astype(str)\n",
    "    \n",
    "    if 'sector_economico' in contexto_geih.columns:\n",
    "        contexto_geih['sector_economico'] = contexto_geih['sector_economico'].astype(str)\n",
    "    \n",
    "    print(f\"   EMICRON - codigo_departamento: {emicron['codigo_departamento'].dtype}\")\n",
    "    print(f\"   EMICRON - sector_economico: {emicron['sector_economico'].dtype}\")\n",
    "    print(f\"   GEIH - codigo_departamento: {contexto_geih['codigo_departamento'].dtype}\")\n",
    "    print(f\"   GEIH - sector_economico: {contexto_geih['sector_economico'].dtype}\")\n",
    "    \n",
    "    antes = len(emicron)\n",
    "    \n",
    "    df_final = emicron.merge(\n",
    "        contexto_geih,\n",
    "        on=['codigo_departamento', 'sector_economico'],\n",
    "        how='left',\n",
    "        suffixes=('', '_geih')\n",
    "    )\n",
    "    \n",
    "    print(f\"   Antes: {antes:,} micronegocios\")\n",
    "    print(f\"   Después: {len(df_final):,} micronegocios\")\n",
    "    print(f\"   Columnas totales: {len(df_final.columns)}\")\n",
    "    \n",
    "    # Verificar match\n",
    "    matched = df_final['ingreso_mediano'].notna().sum() if 'ingreso_mediano' in df_final.columns else 0\n",
    "    print(f\"   Micronegocios con contexto GEIH: {matched:,} ({matched/len(df_final)*100:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 4: CREAR VARIABLE OBJETIVO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 4: CREAR VARIABLE OBJETIVO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_final' in locals():\n",
    "    print(\"\\n[5/9] Definiendo variable objetivo...\")\n",
    "    \n",
    "    # OPCION A: Éxito basado en ingresos relativos al sector\n",
    "    if 'ingresos_totales_declarados' in df_final.columns and 'ingreso_mediano' in df_final.columns:\n",
    "        # Convertir a numérico\n",
    "        df_final['ingresos_totales_declarados'] = pd.to_numeric(df_final['ingresos_totales_declarados'], errors='coerce')\n",
    "        df_final['ingreso_mediano'] = pd.to_numeric(df_final['ingreso_mediano'], errors='coerce')\n",
    "        \n",
    "        # Éxito = ingresos por encima de la mediana del sector en el departamento\n",
    "        df_final['exito_ingresos'] = (\n",
    "            df_final['ingresos_totales_declarados'] > df_final['ingreso_mediano']\n",
    "        ).astype(int)\n",
    "        \n",
    "        print(f\"   Variable objetivo 'exito_ingresos' creada\")\n",
    "        print(f\"   Distribución:\")\n",
    "        print(df_final['exito_ingresos'].value_counts())\n",
    "        print(f\"   Balance: {df_final['exito_ingresos'].mean()*100:.1f}% exitosos\")\n",
    "    \n",
    "    # OPCION B: Índice compuesto de éxito\n",
    "    componentes = []\n",
    "    pesos = []\n",
    "    \n",
    "    # Componente 1: Ingresos (40%)\n",
    "    if 'ingresos_totales_declarados' in df_final.columns:\n",
    "        df_final['ingresos_norm'] = (df_final['ingresos_totales_declarados'] - df_final['ingresos_totales_declarados'].min()) / \\\n",
    "                                     (df_final['ingresos_totales_declarados'].max() - df_final['ingresos_totales_declarados'].min())\n",
    "        componentes.append(df_final['ingresos_norm'])\n",
    "        pesos.append(0.4)\n",
    "    \n",
    "    # Componente 2: Antigüedad (20%)\n",
    "    if 'antiguedad_negocio' in df_final.columns:\n",
    "        df_final['antiguedad_norm'] = (df_final['antiguedad_negocio'] - df_final['antiguedad_negocio'].min()) / \\\n",
    "                                       (df_final['antiguedad_negocio'].max() - df_final['antiguedad_negocio'].min())\n",
    "        componentes.append(df_final['antiguedad_norm'])\n",
    "        pesos.append(0.2)\n",
    "    \n",
    "    # Componente 3: Rentabilidad (20%)\n",
    "    if 'margen_bruto' in df_final.columns:\n",
    "        df_final['margen_norm'] = (df_final['margen_bruto'] - df_final['margen_bruto'].min()) / \\\n",
    "                                   (df_final['margen_bruto'].max() - df_final['margen_bruto'].min())\n",
    "        componentes.append(df_final['margen_norm'])\n",
    "        pesos.append(0.2)\n",
    "    \n",
    "    # Componente 4: Madurez digital (20%)\n",
    "    if 'indice_madurez_digital' in df_final.columns:\n",
    "        df_final['digital_norm'] = df_final['indice_madurez_digital'] / 100\n",
    "        componentes.append(df_final['digital_norm'])\n",
    "        pesos.append(0.2)\n",
    "    \n",
    "    # Calcular índice compuesto si hay componentes\n",
    "    if componentes:\n",
    "        # Normalizar pesos para que sumen 1\n",
    "        pesos_norm = np.array(pesos) / sum(pesos)\n",
    "        \n",
    "        # Calcular índice\n",
    "        indice = sum(c.fillna(0) * p for c, p in zip(componentes, pesos_norm))\n",
    "        df_final['indice_exito'] = indice * 100\n",
    "        \n",
    "        # Variable binaria: éxito si índice > 50\n",
    "        df_final['exito_compuesto'] = (df_final['indice_exito'] > 50).astype(int)\n",
    "        \n",
    "        print(f\"\\n   Variable objetivo 'exito_compuesto' creada\")\n",
    "        print(f\"   Componentes: {len(componentes)}\")\n",
    "        print(f\"   Distribución:\")\n",
    "        print(df_final['exito_compuesto'].value_counts())\n",
    "        print(f\"   Balance: {df_final['exito_compuesto'].mean()*100:.1f}% exitosos\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 5: LIMPIEZA FINAL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 5: LIMPIEZA FINAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_final' in locals():\n",
    "    print(\"\\n[6/9] Limpieza de dataset final...\")\n",
    "    \n",
    "    # Eliminar duplicados\n",
    "    antes = len(df_final)\n",
    "    df_final = df_final.drop_duplicates(subset=['id_micronegocio'])\n",
    "    print(f\"   Duplicados eliminados: {antes - len(df_final):,}\")\n",
    "    \n",
    "    # Reporte de valores perdidos\n",
    "    missing_total = df_final.isnull().sum().sum()\n",
    "    print(f\"   Valores perdidos totales: {missing_total:,}\")\n",
    "    \n",
    "    # Top 10 columnas con más missing\n",
    "    missing_cols = df_final.isnull().sum().sort_values(ascending=False).head(10)\n",
    "    if missing_cols.sum() > 0:\n",
    "        print(f\"\\n   Top 10 columnas con missing:\")\n",
    "        for col, count in missing_cols.items():\n",
    "            pct = count / len(df_final) * 100\n",
    "            print(f\"     {col}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 6: SELECCIONAR COLUMNAS RELEVANTES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 6: SELECCION DE FEATURES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_final' in locals():\n",
    "    print(\"\\n[7/9] Identificando features relevantes...\")\n",
    "    \n",
    "    # Columnas a MANTENER (features para ML)\n",
    "    cols_relevantes = []\n",
    "    \n",
    "    # Identificadores\n",
    "    cols_relevantes.extend(['id_micronegocio'])\n",
    "    \n",
    "    # Variables objetivo\n",
    "    if 'exito_ingresos' in df_final.columns:\n",
    "        cols_relevantes.append('exito_ingresos')\n",
    "    if 'exito_compuesto' in df_final.columns:\n",
    "        cols_relevantes.append('exito_compuesto')\n",
    "    if 'indice_exito' in df_final.columns:\n",
    "        cols_relevantes.append('indice_exito')\n",
    "    \n",
    "    # Ubicación\n",
    "    for col in ['codigo_departamento', 'nombre_departamento', 'area_urbana', 'area']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # Características del negocio\n",
    "    for col in ['sector_economico', 'antiguedad_negocio', 'tipo_establecimiento', \n",
    "                'formalidad', 'num_trabajadores']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # Variables económicas\n",
    "    for col in ['ingresos_totales_declarados', 'costos_totales', 'margen_bruto',\n",
    "                'ratio_costos_ventas', 'activos_totales', 'intensidad_capital']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # Inclusión financiera\n",
    "    for col in ['num_productos_financieros', 'acceso_credito', 'usa_banca_digital',\n",
    "                'indice_inclusion_financiera']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # Emprendimiento\n",
    "    for col in ['tipo_emprendimiento', 'experiencia_previa', 'motivo_principal']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # TIC\n",
    "    for col in ['acceso_internet', 'num_dispositivos', 'num_canales_digitales',\n",
    "                'indice_madurez_digital', 'presencia_digital']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # Contexto GEIH\n",
    "    for col in ['ingreso_mediano', 'ingreso_promedio', 'num_emprendedores']:\n",
    "        if col in df_final.columns:\n",
    "            cols_relevantes.append(col)\n",
    "    \n",
    "    # Filtrar solo las que existen\n",
    "    cols_finales = [c for c in cols_relevantes if c in df_final.columns]\n",
    "    \n",
    "    # Agregar columnas numéricas adicionales que no estén en la lista\n",
    "    numericas = df_final.select_dtypes(include=[np.number]).columns\n",
    "    for col in numericas:\n",
    "        if col not in cols_finales and not col.startswith('Unnamed'):\n",
    "            cols_finales.append(col)\n",
    "    \n",
    "    # Dataset final reducido\n",
    "    df_ml = df_final[cols_finales].copy()\n",
    "    \n",
    "    print(f\"   Columnas seleccionadas: {len(cols_finales)}\")\n",
    "    print(f\"   Dataset ML: {df_ml.shape}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 7: GUARDAR DATASETS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 7: GUARDANDO DATASETS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_final' in locals():\n",
    "    print(\"\\n[8/9] Guardando archivos...\")\n",
    "    \n",
    "    # Dataset completo\n",
    "    df_final.to_csv(f'{OUTPUT_DIR}/dataset_maestro_completo.csv', index=False, encoding='utf-8-sig')\n",
    "    size_completo = os.path.getsize(f'{OUTPUT_DIR}/dataset_maestro_completo.csv') / (1024*1024)\n",
    "    print(f\"   dataset_maestro_completo.csv: {df_final.shape} ({size_completo:.1f} MB)\")\n",
    "    \n",
    "    # Dataset para ML (reducido)\n",
    "    if 'df_ml' in locals():\n",
    "        df_ml.to_csv(f'{OUTPUT_DIR}/dataset_ml.csv', index=False, encoding='utf-8-sig')\n",
    "        size_ml = os.path.getsize(f'{OUTPUT_DIR}/dataset_ml.csv') / (1024*1024)\n",
    "        print(f\"   dataset_ml.csv: {df_ml.shape} ({size_ml:.1f} MB)\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 8: ESTADISTICAS Y VISUALIZACIONES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 8: ESTADISTICAS DESCRIPTIVAS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_ml' in locals():\n",
    "    print(\"\\n[9/9] Generando estadísticas...\")\n",
    "    \n",
    "    # Resumen de variable objetivo\n",
    "    if 'exito_ingresos' in df_ml.columns:\n",
    "        print(f\"\\nVariable objetivo 'exito_ingresos':\")\n",
    "        print(df_ml['exito_ingresos'].value_counts())\n",
    "        print(f\"  Balance: {df_ml['exito_ingresos'].mean()*100:.1f}% exitosos\")\n",
    "    \n",
    "    if 'exito_compuesto' in df_ml.columns:\n",
    "        print(f\"\\nVariable objetivo 'exito_compuesto':\")\n",
    "        print(df_ml['exito_compuesto'].value_counts())\n",
    "        print(f\"  Balance: {df_ml['exito_compuesto'].mean()*100:.1f}% exitosos\")\n",
    "    \n",
    "    # Tipos de datos\n",
    "    print(f\"\\nTipos de datos:\")\n",
    "    print(df_ml.dtypes.value_counts())\n",
    "    \n",
    "    # Missing por columna\n",
    "    missing_pct = (df_ml.isnull().sum() / len(df_ml) * 100).sort_values(ascending=False)\n",
    "    missing_importantes = missing_pct[missing_pct > 10]\n",
    "    if len(missing_importantes) > 0:\n",
    "        print(f\"\\nColumnas con >10% missing:\")\n",
    "        for col, pct in missing_importantes.items():\n",
    "            print(f\"  {col}: {pct:.1f}%\")\n",
    "    \n",
    "    # Estadísticas básicas de features numéricas clave\n",
    "    if 'ingresos_totales_declarados' in df_ml.columns:\n",
    "        print(f\"\\nIngresos totales:\")\n",
    "        print(f\"  Mediana: ${df_ml['ingresos_totales_declarados'].median():,.0f}\")\n",
    "        print(f\"  Promedio: ${df_ml['ingresos_totales_declarados'].mean():,.0f}\")\n",
    "    \n",
    "    if 'indice_madurez_digital' in df_ml.columns:\n",
    "        print(f\"\\nMadurez digital:\")\n",
    "        print(f\"  Mediana: {df_ml['indice_madurez_digital'].median():.1f}/100\")\n",
    "        print(f\"  Promedio: {df_ml['indice_madurez_digital'].mean():.1f}/100\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 9: VISUALIZACIONES RAPIDAS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PASO 9: VISUALIZACIONES\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_ml' in locals():\n",
    "    print(\"\\nGenerando gráficos rápidos...\")\n",
    "    \n",
    "    # Configurar estilo\n",
    "    plt.style.use('seaborn-v0_8-whitegrid')\n",
    "    \n",
    "    # Figura 1: Distribución variable objetivo\n",
    "    \n",
    "# =============================================================================\n",
    "# RESUMEN FINAL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN FINAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if 'df_ml' in locals():\n",
    "    print(f\"\\n✓ FUSION COMPLETADA CON EXITO\")\n",
    "    print(f\"\\nDatasets generados en '{OUTPUT_DIR}/':\")\n",
    "    print(f\"  1. dataset_maestro_completo.csv - Todas las columnas\")\n",
    "    print(f\"  2. dataset_ml.csv - Columnas seleccionadas para ML\")\n",
    "    print(f\"\\nDimensiones finales:\")\n",
    "    print(f\"  Micronegocios: {len(df_ml):,}\")\n",
    "    print(f\"  Features: {len(df_ml.columns)}\")\n",
    "    print(f\"  Variable objetivo: {'exito_ingresos' if 'exito_ingresos' in df_ml.columns else 'exito_compuesto'}\")\n",
    "    \n",
    "    if 'exito_ingresos' in df_ml.columns:\n",
    "        balance = df_ml['exito_ingresos'].mean() * 100\n",
    "        print(f\"  Balance de clases: {balance:.1f}% / {100-balance:.1f}%\")\n",
    "    \n",
    "    print(f\"\\n\" + \"=\"*80)\n",
    "    print(\"PROXIMO PASO: Ejecutar modelo baseline\")\n",
    "    print(\"  python 02_modelo_baseline.py\")\n",
    "    print(\"=\"*80)\n",
    "else:\n",
    "    print(\"\\n✗ ERROR EN LA FUSION\")\n",
    "    print(\"Revisa que todos los archivos existan en las rutas correctas\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d56ee456-bc1b-4a1a-a31b-253e8cc34fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas a eliminar (10):\n",
      "  - ingreso_mediano: 100.0% missing\n",
      "  - ingreso_promedio: 100.0% missing\n",
      "  - num_emprendedores: 100.0% missing\n",
      "  - mes_num: 100.0% missing\n",
      "  - mes_sin: 100.0% missing\n",
      "  - mes_cos: 100.0% missing\n",
      "  - otros_costos: 100.0% missing\n",
      "  - otros_gastos: 100.0% missing\n",
      "  - otro_credito: 99.9% missing\n",
      "  - indice_contexto_favorable: 100.0% missing\n",
      "\n",
      "Dataset limpio:\n",
      "  Antes: (68702, 377)\n",
      "  Después: (68702, 367)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv('FUSION EMICRON 2024 + GEIH 2023/dataset_ml.csv')\n",
    "\n",
    "# Identificar columnas con >90% missing\n",
    "threshold = 0.9\n",
    "missing_pct = df.isnull().sum() / len(df)\n",
    "cols_to_drop = missing_pct[missing_pct > threshold].index.tolist()\n",
    "\n",
    "print(f\"Columnas a eliminar ({len(cols_to_drop)}):\")\n",
    "for col in cols_to_drop:\n",
    "    print(f\"  - {col}: {missing_pct[col]*100:.1f}% missing\")\n",
    "\n",
    "# Eliminar columnas\n",
    "df_clean = df.drop(columns=cols_to_drop)\n",
    "\n",
    "print(f\"\\nDataset limpio:\")\n",
    "print(f\"  Antes: {df.shape}\")\n",
    "print(f\"  Después: {df_clean.shape}\")\n",
    "\n",
    "# Guardar\n",
    "df_clean.to_csv('dataset_ml_clean.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b123bd7f-0d2c-4265-ac7b-1d45a7ce34c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "LIMPIEZA DATASET_ML\n",
      "================================================================================\n",
      "\n",
      "[1/6] Cargando dataset...\n",
      "  Dimensiones: (68702, 377)\n",
      "  Tamaño: 116.2 MB\n",
      "\n",
      "[2/6] Eliminando columnas duplicadas...\n",
      "  No se encontraron duplicadas con _x/_y\n",
      "  Encontradas 66 columnas con sufijos de módulos\n",
      "  Eliminadas: 66\n",
      "\n",
      "[3/6] Eliminando columnas vacías...\n",
      "  Encontradas 9 columnas con >90% missing\n",
      "    - ingreso_mediano: 100.0% vacío\n",
      "    - ingreso_promedio: 100.0% vacío\n",
      "    - num_emprendedores: 100.0% vacío\n",
      "    - mes_num: 100.0% vacío\n",
      "    - mes_sin: 100.0% vacío\n",
      "    - mes_cos: 100.0% vacío\n",
      "    - otros_gastos: 100.0% vacío\n",
      "    - otro_credito: 99.9% vacío\n",
      "    - indice_contexto_favorable: 100.0% vacío\n",
      "  Eliminadas: 9\n",
      "\n",
      "[4/6] Eliminando columnas redundantes...\n",
      "  Eliminando 8 IDs secundarios\n",
      "  Eliminando 2 factores de expansión\n",
      "\n",
      "[5/6] Optimizando tipos de datos...\n",
      "  Memoria antes: 156.2 MB\n",
      "  Memoria después: 152.6 MB\n",
      "  Reducción: 3.6 MB (2.3%)\n",
      "\n",
      "[6/6] Seleccionando columnas necesarias para ML...\n",
      "  Columnas antes: 292\n",
      "  Columnas seleccionadas: 196\n",
      "\n",
      "================================================================================\n",
      "GUARDANDO DATASET LIMPIO\n",
      "================================================================================\n",
      "\n",
      "✓ Guardado: FUSION EMICRON 2024 + GEIH 2023/dataset_ml_clean.csv\n",
      "\n",
      "Comparación:\n",
      "  ANTES:\n",
      "    Archivo: dataset_ml.csv\n",
      "    Dimensiones: (68702, 292)\n",
      "    Tamaño: 116.2 MB\n",
      "\n",
      "  DESPUÉS:\n",
      "    Archivo: dataset_ml_clean.csv\n",
      "    Dimensiones: (68702, 196)\n",
      "    Tamaño: 60.7 MB\n",
      "\n",
      "  REDUCCIÓN:\n",
      "    Columnas eliminadas: 96\n",
      "    Tamaño reducido: 55.5 MB (47.8%)\n",
      "\n",
      "================================================================================\n",
      "COLUMNAS EN DATASET LIMPIO\n",
      "================================================================================\n",
      "\n",
      "Identificación (11):\n",
      "  - id_micronegocio\n",
      "  - codigo_departamento\n",
      "  - nombre_departamento\n",
      "  - formalidad_laboral\n",
      "  - formalidad_fiscal\n",
      "  - ingresos_subsidios\n",
      "  - indice_calidad_empleo\n",
      "  - capacidad_ahorro\n",
      "  - emprendedor_oportunidad\n",
      "  - emprendedor_necesidad\n",
      "  ... y 1 más\n",
      "\n",
      "Objetivo (3):\n",
      "  - exito_ingresos\n",
      "  - exito_compuesto\n",
      "  - indice_exito\n",
      "\n",
      "Ubicación (4):\n",
      "  - codigo_departamento\n",
      "  - nombre_departamento\n",
      "  - area_urbana\n",
      "  - area\n",
      "\n",
      "Negocio (7):\n",
      "  - antiguedad_negocio\n",
      "  - tipo_local\n",
      "  - antiguedad_log\n",
      "  - antiguedad_negocio_norm\n",
      "  - formalidad_laboral\n",
      "  - formalidad_fiscal\n",
      "  - antiguedad_norm\n",
      "\n",
      "Económicas (113):\n",
      "  - exito_ingresos\n",
      "  - ingresos_totales_declarados\n",
      "  - costos_totales\n",
      "  - ventas_habituales\n",
      "  - ventas_habituales_log\n",
      "  - ventas_no_habituales\n",
      "  - ventas_no_habituales_wins\n",
      "  - ingresos_servicios\n",
      "  - ingresos_servicios_log\n",
      "  - ingresos_comercio\n",
      "  ... y 103 más\n",
      "\n",
      "Personal (9):\n",
      "  - numero_trabajadores\n",
      "  - trabajadores_familiares\n",
      "  - trabajadores_no_familiares\n",
      "  - trabajadores_permanentes\n",
      "  - trabajadores_temporales\n",
      "  - trabajadores_remunerados\n",
      "  - trabajadores_no_remunerados\n",
      "  - trabajadores_mujeres\n",
      "  - indice_calidad_empleo\n",
      "\n",
      "Financieras (33):\n",
      "  - ventas_credito\n",
      "  - ventas_credito_norm\n",
      "  - no_credito_ingresos\n",
      "  - credito_compra_activos\n",
      "  - acceso_credito\n",
      "  - porcentaje_credito\n",
      "  - porcentaje_credito_norm\n",
      "  - opera_credito\n",
      "  - tarjeta_credito\n",
      "  - credito_bancario\n",
      "  ... y 23 más\n",
      "\n",
      "TIC (17):\n",
      "  - ventas_otro_canal\n",
      "  - acceso_internet\n",
      "  - num_dispositivos\n",
      "  - num_canales_digitales\n",
      "  - indice_madurez_digital\n",
      "  - presencia_digital\n",
      "  - billetera_digital\n",
      "  - dispositivo_internet\n",
      "  - uso_otro_dispositivo\n",
      "  - uso_plataformas_digitales\n",
      "  ... y 7 más\n",
      "\n",
      "Emprendimiento (4):\n",
      "  - experiencia_previa\n",
      "  - tiene_experiencia\n",
      "  - emprendedor_oportunidad\n",
      "  - emprendedor_necesidad\n",
      "\n",
      "Departamentales (3):\n",
      "  - pib_per_capita\n",
      "  - tasa_pobreza\n",
      "  - indice_competitividad\n",
      "\n",
      "================================================================================\n",
      "LIMPIEZA COMPLETADA\n",
      "================================================================================\n",
      "\n",
      "Usar para modelado: FUSION EMICRON 2024 + GEIH 2023/dataset_ml_clean.csv\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "LIMPIEZA DATASET_ML: Reducir de 116 MB a ~20 MB\n",
    "Elimina columnas innecesarias, duplicadas y vacías\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"LIMPIEZA DATASET_ML\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 1: CARGAR\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[1/6] Cargando dataset...\")\n",
    "df = pd.read_csv('FUSION EMICRON 2024 + GEIH 2023/dataset_ml.csv')\n",
    "size_inicial = os.path.getsize('FUSION EMICRON 2024 + GEIH 2023/dataset_ml.csv') / (1024*1024)\n",
    "\n",
    "print(f\"  Dimensiones: {df.shape}\")\n",
    "print(f\"  Tamaño: {size_inicial:.1f} MB\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 2: ELIMINAR COLUMNAS DUPLICADAS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[2/6] Eliminando columnas duplicadas...\")\n",
    "\n",
    "# Identificar columnas con sufijos (_x, _y, etc.)\n",
    "sufijos_duplicados = ['_x', '_y']\n",
    "cols_duplicadas = []\n",
    "\n",
    "for col in df.columns:\n",
    "    if any(col.endswith(suf) for suf in sufijos_duplicados):\n",
    "        # Si existe versión sin sufijo, eliminar la con sufijo\n",
    "        base_name = col.rsplit('_', 1)[0]\n",
    "        if base_name in df.columns:\n",
    "            cols_duplicadas.append(col)\n",
    "\n",
    "if cols_duplicadas:\n",
    "    print(f\"  Encontradas {len(cols_duplicadas)} columnas duplicadas\")\n",
    "    df = df.drop(columns=cols_duplicadas)\n",
    "    print(f\"  Eliminadas: {len(cols_duplicadas)}\")\n",
    "else:\n",
    "    print(f\"  No se encontraron duplicadas con _x/_y\")\n",
    "\n",
    "# Eliminar columnas con sufijos de módulos (son redundantes)\n",
    "sufijos_modulos = ['_identificacion', '_caracteristicas', '_ventas', '_costos', \n",
    "                   '_inclusion', '_personal', '_emprendimiento', '_tic', '_factores']\n",
    "\n",
    "cols_sufijos_mod = [col for col in df.columns if any(suf in col.lower() for suf in sufijos_modulos)]\n",
    "if cols_sufijos_mod:\n",
    "    print(f\"  Encontradas {len(cols_sufijos_mod)} columnas con sufijos de módulos\")\n",
    "    df = df.drop(columns=cols_sufijos_mod)\n",
    "    print(f\"  Eliminadas: {len(cols_sufijos_mod)}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 3: ELIMINAR COLUMNAS VACÍAS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[3/6] Eliminando columnas vacías...\")\n",
    "\n",
    "# Columnas con >90% missing\n",
    "threshold = 0.9\n",
    "missing_pct = df.isnull().sum() / len(df)\n",
    "cols_vacias = missing_pct[missing_pct > threshold].index.tolist()\n",
    "\n",
    "if cols_vacias:\n",
    "    print(f\"  Encontradas {len(cols_vacias)} columnas con >90% missing\")\n",
    "    for col in cols_vacias[:10]:\n",
    "        print(f\"    - {col}: {missing_pct[col]*100:.1f}% vacío\")\n",
    "    if len(cols_vacias) > 10:\n",
    "        print(f\"    ... y {len(cols_vacias)-10} más\")\n",
    "    \n",
    "    df = df.drop(columns=cols_vacias)\n",
    "    print(f\"  Eliminadas: {len(cols_vacias)}\")\n",
    "else:\n",
    "    print(f\"  No se encontraron columnas vacías\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 4: ELIMINAR COLUMNAS REDUNDANTES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[4/6] Eliminando columnas redundantes...\")\n",
    "\n",
    "# IDs secundarios (mantener solo id_micronegocio)\n",
    "cols_ids = [col for col in df.columns if any(x in col.lower() for x in \n",
    "            ['secuencia', 'orden', 'hogar_secundario', 'registro', 'regis'])]\n",
    "\n",
    "if cols_ids:\n",
    "    # Mantener id_micronegocio, eliminar otros IDs\n",
    "    cols_ids_eliminar = [c for c in cols_ids if c != 'id_micronegocio']\n",
    "    if cols_ids_eliminar:\n",
    "        print(f\"  Eliminando {len(cols_ids_eliminar)} IDs secundarios\")\n",
    "        df = df.drop(columns=cols_ids_eliminar)\n",
    "\n",
    "# Factores de expansión (no útiles para ML)\n",
    "cols_fex = [col for col in df.columns if 'fex' in col.lower() or 'factor_expansion' in col.lower()]\n",
    "if cols_fex:\n",
    "    print(f\"  Eliminando {len(cols_fex)} factores de expansión\")\n",
    "    df = df.drop(columns=cols_fex)\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 5: OPTIMIZAR TIPOS DE DATOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[5/6] Optimizando tipos de datos...\")\n",
    "\n",
    "# Convertir object → category (reduce 70% memoria)\n",
    "cols_object = df.select_dtypes(include=['object']).columns\n",
    "mem_antes = df.memory_usage(deep=True).sum() / (1024*1024)\n",
    "\n",
    "for col in cols_object:\n",
    "    if df[col].nunique() < len(df) * 0.5:  # Si tiene menos del 50% valores únicos\n",
    "        df[col] = df[col].astype('category')\n",
    "\n",
    "mem_despues = df.memory_usage(deep=True).sum() / (1024*1024)\n",
    "print(f\"  Memoria antes: {mem_antes:.1f} MB\")\n",
    "print(f\"  Memoria después: {mem_despues:.1f} MB\")\n",
    "print(f\"  Reducción: {mem_antes - mem_despues:.1f} MB ({(1-mem_despues/mem_antes)*100:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 6: SELECCIONAR SOLO COLUMNAS NECESARIAS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[6/6] Seleccionando columnas necesarias para ML...\")\n",
    "\n",
    "# Categorías de columnas a MANTENER\n",
    "columnas_mantener = []\n",
    "\n",
    "# 1. ID\n",
    "if 'id_micronegocio' in df.columns:\n",
    "    columnas_mantener.append('id_micronegocio')\n",
    "\n",
    "# 2. Variables objetivo\n",
    "vars_objetivo = [c for c in df.columns if 'exito' in c.lower() or 'indice_exito' in c.lower()]\n",
    "columnas_mantener.extend(vars_objetivo)\n",
    "\n",
    "# 3. Ubicación\n",
    "for col in ['codigo_departamento', 'nombre_departamento', 'area_urbana', 'area', 'area_urbano_rural']:\n",
    "    if col in df.columns:\n",
    "        columnas_mantener.append(col)\n",
    "\n",
    "# 4. Sector económico\n",
    "for col in ['sector_economico', 'rama_actividad', 'actividad_economica']:\n",
    "    if col in df.columns and col not in columnas_mantener:\n",
    "        columnas_mantener.append(col)\n",
    "\n",
    "# 5. Características del negocio\n",
    "keywords_negocio = ['antiguedad', 'tipo_establecimiento', 'formalidad', 'local', 'ubicacion']\n",
    "for col in df.columns:\n",
    "    if any(kw in col.lower() for kw in keywords_negocio) and col not in columnas_mantener:\n",
    "        columnas_mantener.append(col)\n",
    "\n",
    "# 6. Variables económicas\n",
    "keywords_economicas = ['ingreso', 'venta', 'costo', 'margen', 'utilidad', 'activo', \n",
    "                       'rentabilidad', 'patrimonio', 'pasivo', 'ganancia']\n",
    "for col in df.columns:\n",
    "    if any(kw in col.lower() for kw in keywords_economicas) and col not in columnas_mantener:\n",
    "        columnas_mantener.append(col)\n",
    "\n",
    "# 7. Personal ocupado\n",
    "keywords_personal = ['trabajador', 'empleado', 'personal', 'calidad_empleo']\n",
    "for col in df.columns:\n",
    "    if any(kw in col.lower() for kw in keywords_personal) and col not in columnas_mantener:\n",
    "        columnas_mantener.append(col)\n",
    "\n",
    "# 8. Financieras\n",
    "keywords_financieras = ['credito', 'banco', 'financiera', 'producto_financiero', \n",
    "                        'inclusion_financiera', 'prestamo', 'ahorro']\n",
    "for col in df.columns:\n",
    "    if any(kw in col.lower() for kw in keywords_financieras) and col not in columnas_mantener:\n",
    "        columnas_mantener.append(col)\n",
    "\n",
    "# 9. TIC\n",
    "keywords_tic = ['internet', 'digital', 'dispositivo', 'computador', 'tecnologia', \n",
    "                'madurez_digital', 'canal', 'web', 'online']\n",
    "for col in df.columns:\n",
    "    if any(kw in col.lower() for kw in keywords_tic) and col not in columnas_mantener:\n",
    "        columnas_mantener.append(col)\n",
    "\n",
    "# 10. Emprendimiento\n",
    "keywords_emprendimiento = ['emprendedor', 'emprendimiento', 'experiencia', 'motivo', 'innovacion']\n",
    "for col in df.columns:\n",
    "    if any(kw in col.lower() for kw in keywords_emprendimiento) and col not in columnas_mantener:\n",
    "        columnas_mantener.append(col)\n",
    "\n",
    "# 11. Factores departamentales\n",
    "keywords_dept = ['pib', 'pobreza', 'competitividad', 'contexto']\n",
    "for col in df.columns:\n",
    "    if any(kw in col.lower() for kw in keywords_dept) and col not in columnas_mantener:\n",
    "        columnas_mantener.append(col)\n",
    "\n",
    "# Filtrar solo las que existen\n",
    "columnas_mantener = [c for c in columnas_mantener if c in df.columns]\n",
    "\n",
    "# Eliminar duplicados\n",
    "columnas_mantener = list(dict.fromkeys(columnas_mantener))\n",
    "\n",
    "print(f\"  Columnas antes: {df.shape[1]}\")\n",
    "print(f\"  Columnas seleccionadas: {len(columnas_mantener)}\")\n",
    "\n",
    "df_clean = df[columnas_mantener].copy()\n",
    "\n",
    "# =============================================================================\n",
    "# GUARDAR\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GUARDANDO DATASET LIMPIO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "output_file = 'FUSION EMICRON 2024 + GEIH 2023/dataset_ml_clean.csv'\n",
    "df_clean.to_csv(output_file, index=False)\n",
    "\n",
    "size_final = os.path.getsize(output_file) / (1024*1024)\n",
    "\n",
    "print(f\"\\n✓ Guardado: {output_file}\")\n",
    "print(f\"\\nComparación:\")\n",
    "print(f\"  ANTES:\")\n",
    "print(f\"    Archivo: dataset_ml.csv\")\n",
    "print(f\"    Dimensiones: {df.shape}\")\n",
    "print(f\"    Tamaño: {size_inicial:.1f} MB\")\n",
    "print(f\"\\n  DESPUÉS:\")\n",
    "print(f\"    Archivo: dataset_ml_clean.csv\")\n",
    "print(f\"    Dimensiones: {df_clean.shape}\")\n",
    "print(f\"    Tamaño: {size_final:.1f} MB\")\n",
    "print(f\"\\n  REDUCCIÓN:\")\n",
    "print(f\"    Columnas eliminadas: {df.shape[1] - df_clean.shape[1]}\")\n",
    "print(f\"    Tamaño reducido: {size_inicial - size_final:.1f} MB ({(1-size_final/size_inicial)*100:.1f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"COLUMNAS EN DATASET LIMPIO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Agrupar por categoría\n",
    "categorias = {\n",
    "    'Identificación': ['id', 'codigo', 'nombre'],\n",
    "    'Objetivo': ['exito', 'indice_exito'],\n",
    "    'Ubicación': ['departamento', 'area', 'ubicacion'],\n",
    "    'Negocio': ['antiguedad', 'tipo', 'establecimiento', 'formalidad'],\n",
    "    'Económicas': ['ingreso', 'venta', 'costo', 'margen', 'utilidad', 'activo'],\n",
    "    'Personal': ['trabajador', 'empleado', 'personal', 'calidad'],\n",
    "    'Financieras': ['credito', 'banco', 'financiera', 'inclusion'],\n",
    "    'TIC': ['internet', 'digital', 'dispositivo', 'madurez', 'canal'],\n",
    "    'Emprendimiento': ['emprendedor', 'experiencia', 'motivo'],\n",
    "    'Departamentales': ['pib', 'pobreza', 'competitividad', 'contexto']\n",
    "}\n",
    "\n",
    "for categoria, keywords in categorias.items():\n",
    "    cols_cat = [c for c in df_clean.columns if any(kw in c.lower() for kw in keywords)]\n",
    "    if cols_cat:\n",
    "        print(f\"\\n{categoria} ({len(cols_cat)}):\")\n",
    "        for col in cols_cat[:10]:\n",
    "            print(f\"  - {col}\")\n",
    "        if len(cols_cat) > 10:\n",
    "            print(f\"  ... y {len(cols_cat)-10} más\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"LIMPIEZA COMPLETADA\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nUsar para modelado: {output_file}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80473429-e918-4316-b59f-099548222b9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
