{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d9b86fd-c4ba-4505-8a25-20aa006fff48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PREPROCESAMIENTO PARA ML\n",
    "Manejo de missing, encoding, split train/test\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PREPROCESAMIENTO PARA MODELADO ML\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 1: CARGAR DATASET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[1/7] Cargando dataset limpio...\")\n",
    "\n",
    "df = pd.read_csv('output_fusion/dataset_ml_clean.csv')\n",
    "\n",
    "print(f\"  Dimensiones: {df.shape}\")\n",
    "print(f\"  Micronegocios: {df.shape[0]:,}\")\n",
    "print(f\"  Features: {df.shape[1]}\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 2: IDENTIFICAR VARIABLE OBJETIVO\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[2/7] Identificando variable objetivo...\")\n",
    "\n",
    "# Buscar variables objetivo\n",
    "vars_objetivo = [c for c in df.columns if 'exito' in c.lower()]\n",
    "\n",
    "if not vars_objetivo:\n",
    "    print(\"  No se encontró variable objetivo, creando una...\")\n",
    "    \n",
    "    # Crear variable objetivo: éxito basado en ingresos\n",
    "    if 'ingresos_totales_declarados' in df.columns:\n",
    "        # Comparar con mediana por sector\n",
    "        if 'sector_economico' in df.columns:\n",
    "            df['mediana_sector'] = df.groupby('sector_economico')['ingresos_totales_declarados'].transform('median')\n",
    "            df['exito'] = (df['ingresos_totales_declarados'] > df['mediana_sector']).astype(int)\n",
    "            print(\"  ✓ Variable 'exito' creada (ingresos > mediana del sector)\")\n",
    "        else:\n",
    "            # Comparar con mediana general\n",
    "            mediana = df['ingresos_totales_declarados'].median()\n",
    "            df['exito'] = (df['ingresos_totales_declarados'] > mediana).astype(int)\n",
    "            print(\"  ✓ Variable 'exito' creada (ingresos > mediana general)\")\n",
    "        \n",
    "        target_col = 'exito'\n",
    "    else:\n",
    "        print(\"  ✗ ERROR: No hay columna de ingresos para crear objetivo\")\n",
    "        exit(1)\n",
    "else:\n",
    "    # Usar la primera variable objetivo encontrada\n",
    "    target_col = vars_objetivo[0]\n",
    "    print(f\"  Variable objetivo: {target_col}\")\n",
    "\n",
    "# Verificar distribución\n",
    "if target_col in df.columns:\n",
    "    print(f\"\\n  Distribución de {target_col}:\")\n",
    "    print(df[target_col].value_counts())\n",
    "    balance = df[target_col].mean() * 100\n",
    "    print(f\"  Balance: {balance:.1f}% clase 1 / {100-balance:.1f}% clase 0\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 3: SEPARAR FEATURES Y TARGET\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[3/7] Separando features y target...\")\n",
    "\n",
    "# Columnas a excluir de features\n",
    "cols_excluir = [target_col, 'id_micronegocio']\n",
    "if 'mediana_sector' in df.columns:\n",
    "    cols_excluir.append('mediana_sector')\n",
    "\n",
    "# Identificar columnas de features\n",
    "feature_cols = [c for c in df.columns if c not in cols_excluir]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df[target_col].copy()\n",
    "\n",
    "print(f\"  Features: {X.shape[1]}\")\n",
    "print(f\"  Target: {y.shape[0]:,} valores\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 4: ANALIZAR Y MANEJAR DATOS FALTANTES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[4/7] Manejando datos faltantes...\")\n",
    "\n",
    "# Reporte de missing\n",
    "missing = X.isnull().sum()\n",
    "missing_pct = (missing / len(X)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'columna': missing.index,\n",
    "    'missing': missing.values,\n",
    "    'porcentaje': missing_pct.values\n",
    "}).sort_values('porcentaje', ascending=False)\n",
    "\n",
    "missing_df = missing_df[missing_df['missing'] > 0]\n",
    "\n",
    "if len(missing_df) > 0:\n",
    "    print(f\"\\n  Columnas con missing: {len(missing_df)}\")\n",
    "    print(f\"\\n  Top 10:\")\n",
    "    for idx, row in missing_df.head(10).iterrows():\n",
    "        print(f\"    {row['columna']:40s}: {row['missing']:8.0f} ({row['porcentaje']:5.1f}%)\")\n",
    "    \n",
    "    # ESTRATEGIA DE IMPUTACIÓN\n",
    "    print(f\"\\n  Aplicando imputación...\")\n",
    "    \n",
    "    # 1. Numéricas: mediana\n",
    "    num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "    for col in num_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            median_val = X[col].median()\n",
    "            X[col] = X[col].fillna(median_val)\n",
    "    \n",
    "    # 2. Categóricas: moda o 'Desconocido'\n",
    "    cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "    for col in cat_cols:\n",
    "        if X[col].isnull().sum() > 0:\n",
    "            if X[col].mode().shape[0] > 0:\n",
    "                X[col] = X[col].fillna(X[col].mode()[0])\n",
    "            else:\n",
    "                X[col] = X[col].fillna('Desconocido')\n",
    "    \n",
    "    missing_after = X.isnull().sum().sum()\n",
    "    print(f\"  Missing antes: {missing.sum():,}\")\n",
    "    print(f\"  Missing después: {missing_after:,}\")\n",
    "else:\n",
    "    print(\"  No hay valores faltantes\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 5: CODIFICAR VARIABLES CATEGORICAS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[5/7] Codificando variables categóricas...\")\n",
    "\n",
    "# Identificar categóricas\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "if len(cat_cols) > 0:\n",
    "    print(f\"  Variables categóricas: {len(cat_cols)}\")\n",
    "    \n",
    "    # LightGBM maneja categóricas nativamente, pero necesitan ser tipo 'category'\n",
    "    for col in cat_cols:\n",
    "        if X[col].dtype == 'object':\n",
    "            X[col] = X[col].astype('category')\n",
    "        \n",
    "        # Imprimir info\n",
    "        n_unique = X[col].nunique()\n",
    "        print(f\"    {col:40s}: {n_unique:4d} categorías\")\n",
    "    \n",
    "    print(f\"  Variables convertidas a tipo 'category'\")\n",
    "else:\n",
    "    print(\"   No hay variables categóricas\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 6: DETECTAR Y MANEJAR OUTLIERS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[6/7] Detectando outliers extremos...\")\n",
    "\n",
    "# Solo en variables numéricas clave\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "outliers_detectados = []\n",
    "for col in num_cols:\n",
    "    Q1 = X[col].quantile(0.25)\n",
    "    Q3 = X[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    \n",
    "    # Outliers extremos (más allá de 3*IQR)\n",
    "    lower_bound = Q1 - 3 * IQR\n",
    "    upper_bound = Q3 + 3 * IQR\n",
    "    \n",
    "    outliers = ((X[col] < lower_bound) | (X[col] > upper_bound)).sum()\n",
    "    \n",
    "    if outliers > 0:\n",
    "        pct = outliers / len(X) * 100\n",
    "        if pct > 1:  # Solo mostrar si >1%\n",
    "            outliers_detectados.append((col, outliers, pct))\n",
    "\n",
    "if outliers_detectados:\n",
    "    print(f\"  Columnas con outliers extremos (>1%):\")\n",
    "    for col, count, pct in sorted(outliers_detectados, key=lambda x: x[2], reverse=True)[:10]:\n",
    "        print(f\"    {col:40s}: {count:6,} ({pct:5.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n  Nota: LightGBM es robusto ante outliers, no se eliminan\")\n",
    "else:\n",
    "    print(\"  No se detectaron outliers extremos significativos\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 7: TRAIN/TEST SPLIT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[7/7] Creando train/test split...\")\n",
    "\n",
    "# Split estratificado (mantiene proporción de clases)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(f\"  Train: {X_train.shape[0]:,} muestras ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "print(f\"  Test:  {X_test.shape[0]:,} muestras ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n  Balance en Train:\")\n",
    "print(f\"    Clase 0: {(y_train==0).sum():,} ({(y_train==0).sum()/len(y_train)*100:.1f}%)\")\n",
    "print(f\"    Clase 1: {(y_train==1).sum():,} ({(y_train==1).sum()/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\n  Balance en Test:\")\n",
    "print(f\"    Clase 0: {(y_test==0).sum():,} ({(y_test==0).sum()/len(y_test)*100:.1f}%)\")\n",
    "print(f\"    Clase 1: {(y_test==1).sum():,} ({(y_test==1).sum()/len(y_test)*100:.1f}%)\")\n",
    "\n",
    "# =============================================================================\n",
    "# GUARDAR DATASETS PROCESADOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GUARDANDO DATASETS PROCESADOS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Guardar train\n",
    "train_df = X_train.copy()\n",
    "train_df[target_col] = y_train\n",
    "train_df.to_csv('output_fusion/train.csv', index=False)\n",
    "print(f\"  train.csv: {train_df.shape}\")\n",
    "\n",
    "# Guardar test\n",
    "test_df = X_test.copy()\n",
    "test_df[target_col] = y_test\n",
    "test_df.to_csv('output_fusion/test.csv', index=False)\n",
    "print(f\"  test.csv: {test_df.shape}\")\n",
    "\n",
    "# Guardar info de features\n",
    "feature_info = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'dtype': X.dtypes.values,\n",
    "    'missing_pct': (X.isnull().sum() / len(X) * 100).values,\n",
    "    'nunique': [X[col].nunique() for col in X.columns]\n",
    "})\n",
    "feature_info.to_csv('output_fusion/feature_info.csv', index=False)\n",
    "print(f\"  feature_info.csv\")\n",
    "\n",
    "# =============================================================================\n",
    "# RESUMEN FINAL\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN FINAL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "Dataset original:\n",
    "  Filas: {df.shape[0]:,}\n",
    "  Columnas: {df.shape[1]}\n",
    "\n",
    "Dataset procesado:\n",
    "  Features: {X.shape[1]}\n",
    "  Target: {target_col}\n",
    "  \n",
    "Train/Test split:\n",
    "  Train: {X_train.shape[0]:,} ({X_train.shape[0]/len(X)*100:.1f}%)\n",
    "  Test:  {X_test.shape[0]:,} ({X_test.shape[0]/len(X)*100:.1f}%)\n",
    "  \n",
    "Tipos de features:\n",
    "  Numéricas: {len(X.select_dtypes(include=[np.number]).columns)}\n",
    "  Categóricas: {len(X.select_dtypes(include=['category']).columns)}\n",
    "  \n",
    "Missing values: {X.isnull().sum().sum()} (todos imputados ✓)\n",
    "\n",
    "Balance de clases:\n",
    "  Train: {(y_train==1).sum()/len(y_train)*100:.1f}% / {(y_train==0).sum()/len(y_train)*100:.1f}%\n",
    "  Test:  {(y_test==1).sum()/len(y_test)*100:.1f}% / {(y_test==0).sum()/len(y_test)*100:.1f}%\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PREPROCESAMIENTO COMPLETADO\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nArchivos generados:\")\n",
    "print(\"  - train.csv (para entrenar)\")\n",
    "print(\"  - test.csv (para evaluar)\")\n",
    "print(\"  - feature_info.csv (metadata)\")\n",
    "print(\"\\nSiguiente paso:\")\n",
    "print(\"  → python 03_modelo_baseline.py\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
