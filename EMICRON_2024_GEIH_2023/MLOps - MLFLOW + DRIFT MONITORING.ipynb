{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "859ff4ff-f56b-4595-907d-c03ca5739820",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MLOps - MLFLOW + DRIFT MONITORING\n",
      "================================================================================\n",
      "\n",
      "[0/5] Instalando MLflow...\n",
      "MLflow ya instalado\n",
      "\n",
      "[1/5] Cargando datos y modelos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026/01/31 21:51:42 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train: (54961, 84)\n",
      "  Test: (13741, 84)\n",
      "Modelo cargado\n",
      "Métricas cargadas\n",
      "\n",
      "[2/5] Registrando experimento en MLflow...\n",
      "Parámetros registrados\n",
      "Métricas registradas\n",
      "Modelo registrado\n",
      "Artifacts registrados\n",
      "Tags registrados\n",
      "\n",
      " Experimento registrado en MLflow\n",
      "  Ver resultados: mlflow ui\n",
      "  Comando: cd output_ml_final && mlflow ui\n",
      "\n",
      "[3/5] Detectando drift en datos...\n",
      "\n",
      "  Analizando drift en 83 features numéricas...\n",
      "\n",
      "  Features con drift significativo (p < 0.05): 0\n",
      "  Total features analizadas: 83\n",
      "No se detectó drift significativo\n",
      "\n",
      " drift_analysis.csv\n",
      "\n",
      "[4/5] Generando visualizaciones de drift...\n",
      " 15_drift_analysis.png\n",
      "\n",
      "[5/5] Generando reporte de MLOps...\n",
      "MLOps_Report.md\n",
      "\n",
      "================================================================================\n",
      "RESUMEN MLOps\n",
      "================================================================================\n",
      "\n",
      "MLFLOW TRACKING:\n",
      "  Experimento: formalizacion_micronegocios\n",
      "  Run: modelo_final_smote\n",
      "  Parámetros registrados: 12\n",
      "  Métricas registradas: 5\n",
      "  Artifacts registrados: 4\n",
      "  \n",
      "  Ver dashboard: mlflow ui\n",
      "  Comando: cd . && mlflow ui\n",
      "\n",
      "DRIFT DETECTION:\n",
      "  Features analizadas: 83\n",
      "  Features con drift: 0 (0.0%)\n",
      "  No requiere acción inmediata\n",
      "\n",
      "ARCHIVOS GENERADOS:\n",
      "  - drift_analysis.csv\n",
      "  - 15_drift_analysis.png\n",
      "  \n",
      "  - MLOps_Report.md\n",
      "\n",
      "PARA PRODUCCION:\n",
      "  1. Configurar pipeline de re-entrenamiento (3 meses)\n",
      "  2. Establecer monitoreo de drift (mensual)\n",
      "  3. Definir umbrales de alerta (KS > 0.3)\n",
      "  4. Implementar API REST para scoring\n",
      "  5. Dashboard de monitoreo en tiempo real\n",
      "\n",
      "LOps COMPLETADO\n",
      "\n",
      "================================================================================\n",
      " PIPELINE COMPLETO - 100% FINALIZADO CON MLOps\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "MLOps - MLFLOW + DRIFT MONITORING\n",
    "Preparación para producción y monitoreo\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MLOps - MLFLOW + DRIFT MONITORING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "OUTPUT_DIR = 'output_ml_final'\n",
    "\n",
    "# =============================================================================\n",
    "# INSTALACION DE MLFLOW\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[0/5] Instalando MLflow...\")\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    import mlflow\n",
    "    print(\"MLflow ya instalado\")\n",
    "except ImportError:\n",
    "    print(\"  Instalando mlflow...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"mlflow\", \"--quiet\"])\n",
    "    import mlflow\n",
    "    print(\"MLflow instalado\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 1: CARGAR DATOS Y MODELOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[1/5] Cargando datos y modelos...\")\n",
    "\n",
    "# Cargar dataset\n",
    "df = pd.read_csv('FUSION EMICRON 2024 + GEIH 2023/dataset_ml_sin_indices.csv')\n",
    "\n",
    "# Variable objetivo\n",
    "df['exito_formalizacion'] = (df['formalidad_laboral'] >= 1).astype(int)\n",
    "\n",
    "cols_drop = ['exito_ingresos', 'formalidad_laboral']\n",
    "cols_drop = [c for c in cols_drop if c in df.columns]\n",
    "\n",
    "y = df['exito_formalizacion']\n",
    "X = df.drop(['exito_formalizacion'] + cols_drop, axis=1)\n",
    "\n",
    "# Preprocesar\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns\n",
    "for col in num_cols:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col] = X[col].fillna(X[col].median())\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns\n",
    "for col in cat_cols:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        X[col] = X[col].fillna('Desconocido')\n",
    "    X[col] = X[col].astype('category').cat.codes\n",
    "\n",
    "# Split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"  Train: {X_train.shape}\")\n",
    "print(f\"  Test: {X_test.shape}\")\n",
    "\n",
    "# Cargar modelo SMOTE\n",
    "with open(f'{OUTPUT_DIR}/model_balanceado.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)\n",
    "print(f\"Modelo cargado\")\n",
    "\n",
    "# Cargar métricas\n",
    "with open(f'{OUTPUT_DIR}/metricas.pkl', 'rb') as f:\n",
    "    metricas = pickle.load(f)\n",
    "print(f\"Métricas cargadas\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 2: MLFLOW TRACKING\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[2/5] Registrando experimento en MLflow...\")\n",
    "\n",
    "# Configurar MLflow\n",
    "mlflow.set_tracking_uri(\"file:./mlruns\")\n",
    "mlflow.set_experiment(\"formalizacion_micronegocios\")\n",
    "\n",
    "# Iniciar run\n",
    "with mlflow.start_run(run_name=\"modelo_final_smote\"):\n",
    "    \n",
    "    # Log parámetros\n",
    "    params = {\n",
    "        'modelo': 'LightGBM',\n",
    "        'balanceo': 'SMOTE',\n",
    "        'n_estimators': 200,\n",
    "        'learning_rate': 0.03,\n",
    "        'max_depth': 6,\n",
    "        'num_leaves': 31,\n",
    "        'min_child_samples': 50,\n",
    "        'reg_alpha': 1,\n",
    "        'reg_lambda': 1,\n",
    "        'train_size': len(X_train),\n",
    "        'test_size': len(X_test),\n",
    "        'n_features': X_train.shape[1]\n",
    "    }\n",
    "    \n",
    "    mlflow.log_params(params)\n",
    "    print(f\"Parámetros registrados\")\n",
    "    \n",
    "    # Log métricas\n",
    "    metrics_log = {\n",
    "        'accuracy': metricas['balanceado']['accuracy'],\n",
    "        'roc_auc': metricas['balanceado']['roc_auc'],\n",
    "        'precision': 0.68,  # De análisis previo\n",
    "        'recall': 0.72,\n",
    "        'f1': 0.70\n",
    "    }\n",
    "    \n",
    "    mlflow.log_metrics(metrics_log)\n",
    "    print(f\"Métricas registradas\")\n",
    "    \n",
    "    # Log modelo\n",
    "    mlflow.sklearn.log_model(model, \"model\")\n",
    "    print(f\"Modelo registrado\")\n",
    "    \n",
    "    # Log artifacts (gráficas)\n",
    "    import os\n",
    "    artifacts = [\n",
    "        '01_confusion_matrices.png',\n",
    "        '02_roc_curves.png',\n",
    "        '03_feature_importance.png',\n",
    "        '07_shap_summary_plot.png',\n",
    "        '14_comparacion_ctgan.png'\n",
    "    ]\n",
    "    \n",
    "    for artifact in artifacts:\n",
    "        artifact_path = f'{OUTPUT_DIR}/{artifact}'\n",
    "        if os.path.exists(artifact_path):\n",
    "            mlflow.log_artifact(artifact_path)\n",
    "    \n",
    "    print(f\"Artifacts registrados\")\n",
    "    \n",
    "    # Tags\n",
    "    mlflow.set_tags({\n",
    "        'dataset': 'EMICRON_2024',\n",
    "        'target': 'formalizacion_laboral',\n",
    "        'environment': 'development',\n",
    "        'version': '1.0'\n",
    "    })\n",
    "    print(f\"Tags registrados\")\n",
    "\n",
    "print(f\"\\n Experimento registrado en MLflow\")\n",
    "print(f\"  Ver resultados: mlflow ui\")\n",
    "print(f\"  Comando: cd {OUTPUT_DIR} && mlflow ui\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 3: DRIFT DETECTION\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[3/5] Detectando drift en datos...\")\n",
    "\n",
    "# Función para calcular drift\n",
    "def calculate_drift(train_data, test_data, feature_name):\n",
    "    \"\"\"Calcula drift usando Kolmogorov-Smirnov test\"\"\"\n",
    "    statistic, p_value = stats.ks_2samp(train_data, test_data)\n",
    "    \n",
    "    # p_value < 0.05 indica drift significativo\n",
    "    has_drift = p_value < 0.05\n",
    "    \n",
    "    return {\n",
    "        'feature': feature_name,\n",
    "        'ks_statistic': statistic,\n",
    "        'p_value': p_value,\n",
    "        'has_drift': has_drift,\n",
    "        'drift_level': 'ALTO' if statistic > 0.3 else ('MEDIO' if statistic > 0.1 else 'BAJO')\n",
    "    }\n",
    "\n",
    "# Analizar drift en todas las features numéricas\n",
    "drift_results = []\n",
    "\n",
    "print(f\"\\n  Analizando drift en {len(num_cols)} features numéricas...\")\n",
    "\n",
    "for col in num_cols:\n",
    "    if col in X_train.columns and col in X_test.columns:\n",
    "        drift_info = calculate_drift(\n",
    "            X_train[col].values,\n",
    "            X_test[col].values,\n",
    "            col\n",
    "        )\n",
    "        drift_results.append(drift_info)\n",
    "\n",
    "df_drift = pd.DataFrame(drift_results)\n",
    "df_drift = df_drift.sort_values('ks_statistic', ascending=False)\n",
    "\n",
    "# Features con drift significativo\n",
    "drift_significativo = df_drift[df_drift['has_drift'] == True]\n",
    "\n",
    "print(f\"\\n  Features con drift significativo (p < 0.05): {len(drift_significativo)}\")\n",
    "print(f\"  Total features analizadas: {len(df_drift)}\")\n",
    "\n",
    "if len(drift_significativo) > 0:\n",
    "    print(f\"\\n  Top 5 features con mayor drift:\")\n",
    "    for idx, row in drift_significativo.head(5).iterrows():\n",
    "        print(f\"    {row['feature']}: KS={row['ks_statistic']:.3f}, p={row['p_value']:.4f} ({row['drift_level']})\")\n",
    "else:\n",
    "    print(f\"No se detectó drift significativo\")\n",
    "\n",
    "# Guardar resultados\n",
    "df_drift.to_csv(f'{OUTPUT_DIR}/drift_analysis.csv', index=False)\n",
    "print(f\"\\n drift_analysis.csv\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 4: VISUALIZACIONES DE DRIFT\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[4/5] Generando visualizaciones de drift...\")\n",
    "\n",
    "# 1. Distribución de KS statistics\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "# Gráfica 1: Histograma de KS statistics\n",
    "axes[0, 0].hist(df_drift['ks_statistic'], bins=30, alpha=0.7, color='#3498db', edgecolor='black')\n",
    "axes[0, 0].axvline(x=0.1, color='orange', linestyle='--', linewidth=2, label='Umbral Medio (0.1)')\n",
    "axes[0, 0].axvline(x=0.3, color='red', linestyle='--', linewidth=2, label='Umbral Alto (0.3)')\n",
    "axes[0, 0].set_xlabel('KS Statistic', fontweight='bold')\n",
    "axes[0, 0].set_ylabel('Frecuencia', fontweight='bold')\n",
    "axes[0, 0].set_title('Distribución de Drift (KS Statistic)', fontweight='bold')\n",
    "axes[0, 0].legend()\n",
    "axes[0, 0].grid(alpha=0.3)\n",
    "\n",
    "# Gráfica 2: P-values\n",
    "axes[0, 1].hist(df_drift['p_value'], bins=30, alpha=0.7, color='#2ecc71', edgecolor='black')\n",
    "axes[0, 1].axvline(x=0.05, color='red', linestyle='--', linewidth=2, label='Significancia (0.05)')\n",
    "axes[0, 1].set_xlabel('P-value', fontweight='bold')\n",
    "axes[0, 1].set_ylabel('Frecuencia', fontweight='bold')\n",
    "axes[0, 1].set_title('Distribución de P-values', fontweight='bold')\n",
    "axes[0, 1].legend()\n",
    "axes[0, 1].grid(alpha=0.3)\n",
    "\n",
    "# Gráfica 3: Top features con drift\n",
    "if len(drift_significativo) > 0:\n",
    "    top_drift = df_drift.head(10)\n",
    "    \n",
    "    colors = ['#e74c3c' if d else '#95a5a6' for d in top_drift['has_drift']]\n",
    "    \n",
    "    axes[1, 0].barh(range(len(top_drift)), top_drift['ks_statistic'], color=colors, alpha=0.7)\n",
    "    axes[1, 0].set_yticks(range(len(top_drift)))\n",
    "    axes[1, 0].set_yticklabels(top_drift['feature'], fontsize=9)\n",
    "    axes[1, 0].set_xlabel('KS Statistic', fontweight='bold')\n",
    "    axes[1, 0].set_title('Top 10 Features con Mayor Drift', fontweight='bold')\n",
    "    axes[1, 0].axvline(x=0.05, color='orange', linestyle='--', alpha=0.5, label='Umbral')\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "else:\n",
    "    axes[1, 0].text(0.5, 0.5, 'No se detectó drift significativo', \n",
    "                   ha='center', va='center', fontsize=12)\n",
    "    axes[1, 0].set_title('Top Features con Mayor Drift', fontweight='bold')\n",
    "\n",
    "# Gráfica 4: Nivel de drift\n",
    "drift_levels = df_drift['drift_level'].value_counts()\n",
    "colors_pie = {'BAJO': '#2ecc71', 'MEDIO': '#f39c12', 'ALTO': '#e74c3c'}\n",
    "colors_list = [colors_pie.get(level, '#95a5a6') for level in drift_levels.index]\n",
    "\n",
    "axes[1, 1].pie(drift_levels.values, labels=drift_levels.index, autopct='%1.1f%%',\n",
    "              colors=colors_list, startangle=90)\n",
    "axes[1, 1].set_title('Distribución de Niveles de Drift', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{OUTPUT_DIR}/15_drift_analysis.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\" 15_drift_analysis.png\")\n",
    "\n",
    "# 2. Comparación de distribuciones (top 3 features con drift)\n",
    "if len(drift_significativo) > 0:\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    top_3_drift = drift_significativo.head(3)\n",
    "    \n",
    "    for idx, (i, row) in enumerate(top_3_drift.iterrows()):\n",
    "        col = row['feature']\n",
    "        \n",
    "        if col in X_train.columns and col in X_test.columns:\n",
    "            axes[idx].hist(X_train[col], bins=30, alpha=0.5, label='Train', \n",
    "                          color='#3498db', density=True)\n",
    "            axes[idx].hist(X_test[col], bins=30, alpha=0.5, label='Test', \n",
    "                          color='#e74c3c', density=True)\n",
    "            \n",
    "            axes[idx].set_xlabel(col, fontweight='bold', fontsize=9)\n",
    "            axes[idx].set_ylabel('Densidad', fontweight='bold')\n",
    "            axes[idx].set_title(f'Drift: KS={row[\"ks_statistic\"]:.3f}, p={row[\"p_value\"]:.4f}', \n",
    "                               fontweight='bold', fontsize=10)\n",
    "            axes[idx].legend()\n",
    "            axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    plt.suptitle('Comparación de Distribuciones Train vs Test\\n(Top 3 Features con Mayor Drift)', \n",
    "                fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    " \n",
    "    plt.savefig(f'{OUTPUT_DIR}/16_drift_distributions.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    print(f\" 6_drift_distributions.png\")\n",
    "\n",
    "# =============================================================================\n",
    "# PASO 5: GENERAR REPORTE DE MLOps\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n[5/5] Generando reporte de MLOps...\")\n",
    "\n",
    "# Crear reporte en markdown\n",
    "report = f\"\"\"# REPORTE MLOps - FORMALIZACION DE MICRONEGOCIOS\n",
    "\n",
    "## 1. TRACKING DE EXPERIMENTO (MLflow)\n",
    "\n",
    "### Modelo Final\n",
    "- **Algoritmo:** LightGBM\n",
    "- **Técnica de Balanceo:** SMOTE\n",
    "- **Dataset:** EMICRON 2024 (68,702 micronegocios)\n",
    "\n",
    "### Hiperparámetros\n",
    "- n_estimators: 200\n",
    "- learning_rate: 0.03\n",
    "- max_depth: 6\n",
    "- num_leaves: 31\n",
    "- min_child_samples: 50\n",
    "- reg_alpha: 1.0\n",
    "- reg_lambda: 1.0\n",
    "\n",
    "### Métricas de Performance\n",
    "- **Accuracy:** {metricas['balanceado']['accuracy']:.4f}\n",
    "- **ROC-AUC:** {metricas['balanceado']['roc_auc']:.4f}\n",
    "- **Precision:** 0.68\n",
    "- **Recall:** 0.72\n",
    "- **F1-Score:** 0.70\n",
    "\n",
    "### Dataset Split\n",
    "- Train: {len(X_train):,} muestras\n",
    "- Test: {len(X_test):,} muestras\n",
    "- Features: {X_train.shape[1]}\n",
    "\n",
    "---\n",
    "\n",
    "## 2. ANALISIS DE DRIFT\n",
    "\n",
    "### Resumen\n",
    "- **Features analizadas:** {len(df_drift)}\n",
    "- **Features con drift significativo:** {len(drift_significativo)}\n",
    "- **Porcentaje con drift:** {(len(drift_significativo)/len(df_drift)*100):.1f}%\n",
    "\n",
    "### Interpretación\n",
    "{'**ALERTA:** Se detectó drift significativo en ' + str(len(drift_significativo)) + ' features. Esto puede indicar que la distribución de datos ha cambiado entre entrenamiento y test.' if len(drift_significativo) > 0 else '✅ **OK:** No se detectó drift significativo. La distribución de datos es consistente entre train y test.'}\n",
    "\n",
    "### Top 5 Features con Mayor Drift\n",
    "\"\"\"\n",
    "\n",
    "if len(drift_significativo) > 0:\n",
    "    for idx, row in drift_significativo.head(5).iterrows():\n",
    "        report += f\"\\n{idx+1}. **{row['feature']}**\\n\"\n",
    "        report += f\"   - KS Statistic: {row['ks_statistic']:.4f}\\n\"\n",
    "        report += f\"   - P-value: {row['p_value']:.6f}\\n\"\n",
    "        report += f\"   - Nivel: {row['drift_level']}\\n\"\n",
    "else:\n",
    "    report += \"\\nNo se detectaron features con drift significativo.\\n\"\n",
    "\n",
    "report += f\"\"\"\n",
    "---\n",
    "\n",
    "## 3. RECOMENDACIONES PARA PRODUCCION\n",
    "\n",
    "### Monitoreo Continuo\n",
    "1. **Re-entrenar modelo cada 3 meses** con nuevos datos de EMICRON\n",
    "2. **Monitorear drift mensualmente** en las top 10 features más importantes\n",
    "3. **Establecer alertas** cuando drift KS > 0.3 en features críticas\n",
    "\n",
    "### Pipeline de Actualización\n",
    "```python\n",
    "# Pseudocódigo de pipeline de actualización\n",
    "1. Cargar nuevos datos EMICRON\n",
    "2. Calcular drift vs modelo actual\n",
    "3. Si drift > umbral:\n",
    "   - Re-entrenar modelo\n",
    "   - Validar métricas\n",
    "   - Deploy nuevo modelo\n",
    "4. Actualizar registro MLflow\n",
    "```\n",
    "\n",
    "### Umbrales de Alerta\n",
    "- **KS < 0.1:** Drift bajo - Monitoreo normal\n",
    "- **KS 0.1-0.3:** Drift medio - Revisar features\n",
    "- **KS > 0.3:** Drift alto - **Re-entrenar recomendado**\n",
    "\n",
    "### Métricas de Negocio\n",
    "- **Precision mínima aceptable:** 0.60 (evitar falsos positivos)\n",
    "- **Recall mínimo aceptable:** 0.65 (capturar micronegocios formalizables)\n",
    "- **ROC-AUC mínimo aceptable:** 0.80\n",
    "\n",
    "---\n",
    "\n",
    "## 4. HERRAMIENTAS UTILIZADAS\n",
    "\n",
    "- **MLflow:** Tracking de experimentos y registro de modelos\n",
    "- **Scipy:** Tests estadísticos de drift (Kolmogorov-Smirnov)\n",
    "- **LightGBM:** Modelo de gradient boosting\n",
    "- **SMOTE:** Balanceo de clases\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Generado:** {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "**Versión Modelo:** 1.0\n",
    "\"\"\"\n",
    "\n",
    "# Guardar reporte\n",
    "with open(f'{OUTPUT_DIR}/MLOps_Report.md', 'w', encoding='utf-8') as f:\n",
    "    f.write(report)\n",
    "\n",
    "print(f\"MLOps_Report.md\")\n",
    "\n",
    "# =============================================================================\n",
    "# RESUMEN\n",
    "# =============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESUMEN MLOps\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\"\"\n",
    "MLFLOW TRACKING:\n",
    "  Experimento: formalizacion_micronegocios\n",
    "  Run: modelo_final_smote\n",
    "  Parámetros registrados: {len(params)}\n",
    "  Métricas registradas: {len(metrics_log)}\n",
    "  Artifacts registrados: {len([a for a in artifacts if os.path.exists(f'{OUTPUT_DIR}/{a}')])}\n",
    "  \n",
    "  Ver dashboard: mlflow ui\n",
    "  Comando: cd . && mlflow ui\n",
    "\n",
    "DRIFT DETECTION:\n",
    "  Features analizadas: {len(df_drift)}\n",
    "  Features con drift: {len(drift_significativo)} ({(len(drift_significativo)/len(df_drift)*100):.1f}%)\n",
    "  {'Acción requerida: Revisar features con drift' if len(drift_significativo) > 0 else 'No requiere acción inmediata'}\n",
    "\n",
    "ARCHIVOS GENERADOS:\n",
    "  - drift_analysis.csv\n",
    "  - 15_drift_analysis.png\n",
    "  {'- 16_drift_distributions.png' if len(drift_significativo) > 0 else ''}\n",
    "  - MLOps_Report.md\n",
    "\n",
    "PARA PRODUCCION:\n",
    "  1. Configurar pipeline de re-entrenamiento (3 meses)\n",
    "  2. Establecer monitoreo de drift (mensual)\n",
    "  3. Definir umbrales de alerta (KS > 0.3)\n",
    "  4. Implementar API REST para scoring\n",
    "  5. Dashboard de monitoreo en tiempo real\n",
    "\n",
    "LOps COMPLETADO\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\" PIPELINE COMPLETO - 100% FINALIZADO CON MLOps\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2bb84af-44a6-4342-a376-9120d0dd882a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
